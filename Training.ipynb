{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181960 entries, 0 to 181959\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   province  181960 non-null  object \n",
      " 1   max       181960 non-null  int64  \n",
      " 2   min       181960 non-null  int64  \n",
      " 3   wind      181960 non-null  int64  \n",
      " 4   wind_d    181960 non-null  object \n",
      " 5   rain      181960 non-null  float64\n",
      " 6   humidi    181960 non-null  int64  \n",
      " 7   cloud     181960 non-null  int64  \n",
      " 8   pressure  181960 non-null  int64  \n",
      " 9   date      181960 non-null  object \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DataPath = './Dataset/VietNamWeather.csv'\n",
    "Dataframe = pd.read_csv(DataPath).reset_index(drop=True)\n",
    "\n",
    "Dataframe.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181960 entries, 0 to 181959\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   temp      181960 non-null  float64\n",
      " 1   wind      181960 non-null  float64\n",
      " 2   humidi    181960 non-null  int64  \n",
      " 3   cloud     181960 non-null  int64  \n",
      " 4   pressure  181960 non-null  int64  \n",
      " 5   israin    181960 non-null  int64  \n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 8.3 MB\n"
     ]
    }
   ],
   "source": [
    "Dataframe['temp'] = (Dataframe['max'] + Dataframe['min']) / 2\n",
    "NewDf = Dataframe[['temp', 'wind', 'humidi', 'cloud', 'pressure']]\n",
    "\n",
    "RainThreshold = 0.5\n",
    "NewDf['israin'] = (Dataframe['rain'] > RainThreshold).astype(int)\n",
    "\n",
    "NewDf['wind'] *= 0.277777778 # km/h to m/s\n",
    "\n",
    "NewDf.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>humidi</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "      <th>israin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.5</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.5</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.5</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp      wind  humidi  cloud  pressure  israin\n",
       "0  24.5  4.722222      90     71      1010       1\n",
       "1  28.0  5.555556      64     24      1010       0\n",
       "2  26.5  3.888889      75     45      1008       0\n",
       "3  27.0  8.333333      79     52      1012       0\n",
       "4  28.0  5.555556      70     24      1010       0\n",
       "5  25.5  3.888889      75     55      1012       0\n",
       "6  26.0  2.777778      75     42      1012       0\n",
       "7  28.0  6.111111      63      9      1015       0\n",
       "8  27.0  5.555556      76     35      1011       0\n",
       "9  26.0  4.444444      70     33      1010       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Data = NewDf.drop(columns='israin').values\n",
    "Target = NewDf['israin'].values\n",
    "\n",
    "np.save('./Data.npy', Data)\n",
    "np.save('./Target.npy', Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Standard scaling', StandardScaler()),\n",
    "     ('Normalize', Normalizer())]).fit(X=Data, y=Target)\n",
    "\n",
    "Data = pipeline.transform(X=Data)\n",
    "Target = LabelEncoder().fit_transform(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGJCAYAAACZwnkIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABB00lEQVR4nO3deVxU9f4/8NcAMiwy4AYDSoIroCgJiGhpJoGJGam5kaKSdgtIxZUK3DM1U9xAuyVe01wvXnPBCLebchXBBTcyw90BFWGUFJD5/P7ox/k6gcqm4PH1fDzm8XA+n/f5nM85DvLyzFkUQggBIiIiIhkwqOkJEBEREVUXBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GG6Jqsm/fPigUCmzevPmFW8+0adOgUCiqbbwXQUJCAtzc3GBiYgKFQoHc3NwKLf8y7jPg/7b71q1b1TrumjVr4OTkhDp16sDKyqpax6aXi1FNT4CoNivvL669e/c+45lQdbp9+zYGDBiANm3aYNmyZVAqlTA3N39u61++fDnMzMwwfPjw57bOx7l+/TpWrlyJgIAAuLm51cgczp07h+HDh6Nnz56YMmUKzMzMamQeJA8MNkRPsGbNGr33//rXv5CYmFiq3dnZGWfPnn2eU6MqSElJwd27dzFz5kz4+Pg89/UvX74cDRs2rDXBZvr06XBwcKixYLNv3z7odDpER0ejRYsWNTIHkg8GG6In+OCDD/Te/+9//0NiYmKpdgAMNi+Q7OxsAOBXHrXEs/j7+PPPP3nk5yXFc2yIqplOp8Ps2bPRpEkTmJiYoEePHvj9999L1R0+fBg9e/aEpaUlzMzM0K1bNxw8eLDc6ykuLsZnn30GtVoNc3Nz9OnTB1euXNGr+e9//4v3338fr7zyCpRKJezt7TFu3Djcv3//qeOvWrUKb775JqytraFUKuHi4oKYmJhSdQ4ODujduzd+/fVXdOzYESYmJmjWrBn+9a9/larNzc3FuHHj4ODgAKVSiSZNmmDYsGF652sUFBRg6tSpaNGihTTnSZMmoaCgoFz7ZdOmTXB3d4epqSkaNmyIDz74ANeuXZP633jjDQQFBQEAPD09oVAonnrk5Ndff4WnpydMTEzQvHlzrFixosy68uwzBwcHnD59Gvv374dCoYBCocAbb7wBAMjJycGECRPg6uqKunXrQqVS4e2338aJEydKrWvJkiVo06YNzMzMUK9ePXh4eGDdunV6NdeuXcPIkSNhY2MDpVKJNm3a4Pvvv5f69+3bB09PTwDAiBEjpPnExcU9cX8AwK1btzBgwACoVCo0aNAAY8aMwYMHD0rV/fDDD9LfR/369TFo0CC9z6mDgwOmTp0KAGjUqBEUCgWmTZsm9S9fvhxt2rSBUqmEnZ0dQkJCSp0P9cYbb6Bt27ZITU1F165dYWZmhs8++wxA1T9P9AISRFRuISEh4nE/Nnv37hUAxKuvvirc3d3FwoULxbRp04SZmZno2LGjXm1SUpIwNjYW3t7eYsGCBWLhwoWiXbt2wtjYWBw+fPiJcyhZj6urq2jXrp345ptvxJQpU4SJiYlo1aqV+PPPP6XasLAw0atXL/Hll1+KFStWiODgYGFoaCj69++vN+bUqVNLbZenp6cYPny4WLhwoViyZInw9fUVAMTSpUv16po2bSpat24tbGxsxGeffSaWLl0qOnToIBQKhTh16pRUd/fuXdG2bVthaGgoRo0aJWJiYsTMmTOFp6enOHbsmBBCiOLiYuHr6yvMzMzE2LFjxYoVK0RoaKgwMjIS77777hP3ixBCrFq1SgAQnp6eYuHChWLKlCnC1NRUODg4iDt37gghhPj555/F6NGjBQAxY8YMsWbNGnHo0KHHjnny5ElhamoqXnnlFTFnzhwxc+ZMYWNjI9q1a1epfRYfHy+aNGkinJycxJo1a8SaNWvEzz//LIQQIiUlRTRv3lxMmTJFrFixQsyYMUM0btxYWFpaimvXrkljrFy5UgAQ/fv3FytWrBDR0dEiODhYfPrpp1KNRqMRTZo0Efb29mLGjBkiJiZG9OnTRwAQCxculGpmzJghAIjRo0dL87lw4cJj90fJZ8XV1VW88847YunSpeKDDz4QAMTQoUP1amfNmiUUCoUYOHCgWL58uZg+fbpo2LCh3t9HfHy8eO+99wQAERMTI9asWSNOnDihty4fHx+xZMkSERoaKgwNDYWnp6coLCyU1tOtWzehVqtFo0aNRFhYmFixYoXYunVrlT9P9GJisCGqgPIEG2dnZ1FQUCC1R0dHCwAiPT1dCCGETqcTLVu2FH5+fkKn00l1f/75p3B0dBRvvfXWE+dQsp7GjRsLrVYrtW/cuFEAENHR0Xpj/t2cOXOEQqEQly5dktrKCjZlLevn5yeaNWum19a0aVMBQBw4cEBqy87OFkqlUowfP15qi4qKEgDEv//971LjluyHNWvWCAMDA/Hf//5Xrz82NlYAEAcPHiy1bInCwkJhbW0t2rZtK+7fvy+1b9++XQAQUVFRUltJAEpJSXnseCUCAgKEiYmJ3v46c+aMMDQ0rPQ+a9OmjejWrVup2gcPHoji4mK9tszMTKFUKsWMGTOktnfffVe0adPmifMODg4Wtra24tatW3rtgwYNEpaWltJcU1JSBACxatWqJ45XouSz0qdPH732Tz75RACQQsnFixeFoaGhmD17tl5denq6MDIy0msvGfPmzZtSW3Z2tjA2Nha+vr56+2Tp0qUCgPj++++ltm7dugkAIjY2Vm9dVfk80YuLX0URVbMRI0bA2NhYev/6668DAP744w8AwPHjx3H+/HkMGTIEt2/fxq1bt3Dr1i3k5+ejR48eOHDgAHQ63VPXM2zYMFhYWEjv+/fvD1tbW+zcuVNqMzU1lf6cn5+PW7duoXPnzhBC4NixY08c/9Fl8/LycOvWLXTr1g1//PEH8vLy9GpdXFyk7QT++kqhdevW0jYDwJYtW9C+fXu89957pdZVcvXZpk2b4OzsDCcnJ2m/3Lp1C2+++SaAJ199dvToUWRnZ+OTTz6BiYmJ1O7v7w8nJyfs2LHjidtbluLiYuzevRsBAQF45ZVXpHZnZ2f4+fmVqq/IPiuLUqmEgYGBtO7bt2+jbt26aN26NdLS0qQ6KysrXL16FSkpKWWOI4TAli1b8M4770AIobcv/fz8kJeXpzdeZYSEhOi9DwsLAwDp8/fvf/8bOp0OAwYM0Fu/Wq1Gy5Ytn3ol4S+//ILCwkKMHTtW2icAMGrUKKhUqlJ/n0qlEiNGjNBrq8rniV5cPHmYqJo9+gsQAOrVqwcAuHPnDgDg/PnzACCd51GWvLw8abnHadmypd57hUKBFi1a4OLFi1Lb5cuXERUVhW3btknrf3QdT3Lw4EFMnToVycnJ+PPPP0sta2lpKb3/+zYDf233o+u8cOEC+vXr98R1nj9/HmfPnkWjRo3K7C85ybQsly5dAgC0bt26VJ+TkxN+/fXXJ667LDdv3sT9+/dL7euS9TwaIoGK7bOylFwZtHz5cmRmZqK4uFjqa9CggfTnyZMn45dffkHHjh3RokUL+Pr6YsiQIejSpYs079zcXKxcuRIrV64sc11P2pfl8fd90rx5cxgYGEifv/Pnz0MIUea+A4A6deo8cfzH/X0aGxujWbNmUn+Jxo0b6/2HomQOlf080YuLwYaomhkaGpbZLoQAAOlozPz58x97eW3dunWrPI/i4mK89dZbyMnJweTJk+Hk5ARzc3Ncu3YNw4cPf+JRoQsXLqBHjx5wcnLCN998A3t7exgbG2Pnzp1YuHBhqWWfts3lpdPp4Orqim+++abMfnt7+wqN9zxVdJ+V5csvv0RkZCRGjhyJmTNnon79+jAwMMDYsWP1lnd2dkZGRga2b9+OhIQEbNmyBcuXL0dUVBSmT58u1X7wwQePDdDt2rWrng3///5+zyedTgeFQoFdu3aV+fmojs/4ox49WvboHF7UzxNVHoMN0XPWvHlzAIBKparSPVRKjvyUEELg999/l35hpaen47fffsPq1asxbNgwqS4xMfGpY//0008oKCjAtm3b9I7GVOXQffPmzXHq1Kmn1pw4cQI9evSo8F19mzZtCgDIyMiQvmookZGRIfVXRKNGjWBqalpqX5eM+aiK7LPHbdvmzZvRvXt3fPfdd3rtubm5aNiwoV6bubk5Bg4ciIEDB6KwsBB9+/bF7NmzERERgUaNGsHCwgLFxcVP/YxV9u7J58+fh6Ojo/T+999/h06ng4ODA4C//i6FEHB0dESrVq0qPP6jf5/NmjWT2gsLC5GZmVmun52qfJ7oxcVzbIieM3d3dzRv3hxff/017t27V6r/5s2b5RrnX//6F+7evSu937x5M27cuIG3334bwP8dRXn0qIkQAtHR0U8du6xl8/LysGrVqnLNrSz9+vXDiRMnEB8fX6qvZD0DBgzAtWvX8O2335aquX//PvLz8x87voeHB6ytrREbG6t3Ke+uXbtw9uxZ+Pv7V3jOhoaG8PPzw9atW3H58mWp/ezZs9i9e3ep2ke3BXj8PjM3Ny/zEQ6GhoaljnJt2rRJ73J14K87Jz/K2NgYLi4uEEKgqKgIhoaG6NevH7Zs2VJmmHz0M1Zyx+WKPlJi2bJleu+XLFkCANLnr2/fvjA0NMT06dNLbZMQotQ2/J2Pjw+MjY2xePFiveW/++475OXllevvsyqfJ3px8YgN0XNmYGCAf/7zn3j77bfRpk0bjBgxAo0bN8a1a9ewd+9eqFQq/PTTT08dp379+njttdcwYsQIZGVlYdGiRWjRogVGjRoF4K/zSpo3b44JEybg2rVrUKlU2LJlS6lzbcri6+sLY2NjvPPOO/joo49w7949fPvtt7C2tsaNGzcqtd0TJ07E5s2b8f7772PkyJFwd3dHTk4Otm3bhtjYWLRv3x5Dhw7Fxo0b8Y9//AN79+5Fly5dUFxcjHPnzmHjxo3YvXs3PDw8yhy/Tp06mDt3LkaMGIFu3bph8ODByMrKQnR0NBwcHDBu3LhKzXv69OlISEjA66+/jk8++QQPHz6U7iFz8uTJSu0zd3d3xMTEYNasWWjRogWsra3x5ptvonfv3pgxYwZGjBiBzp07Iz09HWvXrtU7YlGyLrVajS5dusDGxgZnz57F0qVL4e/vL51Q/tVXX2Hv3r3w8vLCqFGj4OLigpycHKSlpeGXX35BTk4OgL+OalhZWSE2NhYWFhYwNzeHl5eX3tGYsmRmZqJPnz7o2bMnkpOT8cMPP2DIkCFo3769NO6sWbMQERGBixcvIiAgABYWFsjMzER8fDxGjx6NCRMmPHb8Ro0aISIiAtOnT0fPnj3Rp08fZGRkYPny5fD09CzzJpl/V5XPE73AnvdlWEQvsvJc7r1p0ya99szMzDIvpz127Jjo27evaNCggVAqlaJp06ZiwIABIikp6YlzKFnPjz/+KCIiIoS1tbUwNTUV/v7+epckC/HXZck+Pj6ibt26omHDhmLUqFHixIkTpeZT1uXe27ZtE+3atRMmJibCwcFBzJ07V3z//fcCgMjMzJTqmjZtKvz9/UvNs1u3bqUuab59+7YIDQ0VjRs3FsbGxqJJkyYiKChI75LkwsJCMXfuXNGmTRuhVCpFvXr1hLu7u5g+fbrIy8t74r4RQogNGzaIV199VSiVSlG/fn0RGBgorl69qldTkcu9hRBi//79wt3dXRgbG4tmzZqJ2NjYKu0zjUYj/P39hYWFhQAg7acHDx6I8ePHC1tbW2Fqaiq6dOkikpOTS+3LFStWiK5du0qfnebNm4uJEyeW2j9ZWVkiJCRE2Nvbizp16gi1Wi169OghVq5cqVf3n//8R7i4uAgjI6OnXvpdst1nzpwR/fv3FxYWFqJevXoiNDRU7zL7Elu2bBGvvfaaMDc3F+bm5sLJyUmEhISIjIyMUmM+erl3iaVLlwonJydRp04dYWNjIz7++GPpHjglunXr9tjL36v6eaIXj0KICp7dR0RERFRL8RwbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDd6g7znS6XS4fv06LCwseHtvIiKiChBC4O7du7Czs9N74vvfMdg8R9evX+dD14iIiKrgypUraNKkyWP7azTYHDhwAPPnz0dqaipu3LiB+Ph4BAQEAACKiorwxRdfYOfOnfjjjz9gaWkJHx8ffPXVV7Czs5PGyMnJQVhYGH766ScYGBigX79+iI6O1nty7MmTJxESEoKUlBQ0atQIYWFhmDRpkt5cNm3ahMjISFy8eBEtW7bE3Llz0atXL6lfCIGpU6fi22+/RW5uLrp06YKYmBi0bNmy3NtbcqvzK1euQKVSVWaXERERvZS0Wi3s7e2l36WPU6PBJj8/H+3bt8fIkSPRt29fvb4///wTaWlpiIyMRPv27XHnzh2MGTMGffr0wdGjR6W6wMBA3LhxA4mJiSgqKsKIESMwevRorFu3DsBfO8LX1xc+Pj6IjY1Feno6Ro4cCSsrK4wePRoAcOjQIQwePBhz5sxB7969sW7dOgQEBCAtLQ1t27YFAMybNw+LFy/G6tWr4ejoiMjISPj5+eHMmTMwMTEp1/aWfP2kUqkYbIiIiCrhqady1OwTHf4PABEfH//EmiNHjggA0vNwzpw5U+p5L7t27RIKhUJcu3ZNCCHE8uXLRb169URBQYFUM3nyZNG6dWvp/YABA0o968bLy0t89NFHQgghdDqdUKvVYv78+VJ/bm6uUCqV4scffyz3Nubl5QkAfD4JERFRBZX3d+gLdVVUXl4eFAoFrKysAADJycmwsrLSezqrj48PDAwMcPjwYamma9euMDY2lmr8/PyQkZEhPeU4OTkZPj4+euvy8/NDcnIygL+eYqvRaPRqLC0t4eXlJdWUpaCgAFqtVu9FREREz84LE2wePHiAyZMnY/DgwdLXOBqNBtbW1np1RkZGqF+/PjQajVRjY2OjV1Py/mk1j/Y/ulxZNWWZM2cOLC0tpRdPHCYiInq2XohgU1RUhAEDBkAIgZiYmJqeTrlFREQgLy9Pel25cqWmp0RERCRrtf5y75JQc+nSJezZs0fvpFu1Wo3s7Gy9+ocPHyInJwdqtVqqycrK0qspef+0mkf7S9psbW31atzc3B47d6VSCaVSWZHNJSIioiqo1UdsSkLN+fPn8csvv6BBgwZ6/d7e3sjNzUVqaqrUtmfPHuh0Onh5eUk1Bw4cQFFRkVSTmJiI1q1bo169elJNUlKS3tiJiYnw9vYGADg6OkKtVuvVaLVaHD58WKohIiKimlejwebevXs4fvw4jh8/DuCvk3SPHz+Oy5cvo6ioCP3798fRo0exdu1aFBcXQ6PRQKPRoLCwEADg7OyMnj17YtSoUThy5AgOHjyI0NBQDBo0SLrXzZAhQ2BsbIzg4GCcPn0aGzZsQHR0NMLDw6V5jBkzBgkJCViwYAHOnTuHadOm4ejRowgNDQXw16VlY8eOxaxZs7Bt2zakp6dj2LBhsLOzk+67Q0RERLXA87lIq2x79+4VAEq9goKCRGZmZpl9AMTevXulMW7fvi0GDx4s6tatK1QqlRgxYoS4e/eu3npOnDghXnvtNaFUKkXjxo3FV199VWouGzduFK1atRLGxsaiTZs2YseOHXr9Op1OREZGChsbG6FUKkWPHj1ERkZGhbaXl3sTERFVTnl/hyqEEKJGEtVLSKvVwtLSEnl5ebxBHxERUQWU93dorT7HhoiIiKgiGGyIiIhINmr95d5ERLKx7inPuCGSkyE1c6YLj9gQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFs1GiwOXDgAN555x3Y2dlBoVBg69atev1CCERFRcHW1hampqbw8fHB+fPn9WpycnIQGBgIlUoFKysrBAcH4969e3o1J0+exOuvvw4TExPY29tj3rx5peayadMmODk5wcTEBK6urti5c2eF50JEREQ1q0aDTX5+Ptq3b49ly5aV2T9v3jwsXrwYsbGxOHz4MMzNzeHn54cHDx5INYGBgTh9+jQSExOxfft2HDhwAKNHj5b6tVotfH190bRpU6SmpmL+/PmYNm0aVq5cKdUcOnQIgwcPRnBwMI4dO4aAgAAEBATg1KlTFZoLERER1SyFEELU9CQAQKFQID4+HgEBAQD+OkJiZ2eH8ePHY8KECQCAvLw82NjYIC4uDoMGDcLZs2fh4uKClJQUeHh4AAASEhLQq1cvXL16FXZ2doiJicHnn38OjUYDY2NjAMCUKVOwdetWnDt3DgAwcOBA5OfnY/v27dJ8OnXqBDc3N8TGxpZrLuWh1WphaWmJvLw8qFSqatlvRPQCWaeo6RkQPT9DqjdelPd3aK09xyYzMxMajQY+Pj5Sm6WlJby8vJCcnAwASE5OhpWVlRRqAMDHxwcGBgY4fPiwVNO1a1cp1ACAn58fMjIycOfOHanm0fWU1JSspzxzKUtBQQG0Wq3ei4iIiJ6dWhtsNBoNAMDGxkav3cbGRurTaDSwtrbW6zcyMkL9+vX1asoa49F1PK7m0f6nzaUsc+bMgaWlpfSyt7d/ylYTERFRVdTaYCMHERERyMvLk15Xrlyp6SkRERHJWq0NNmq1GgCQlZWl156VlSX1qdVqZGdn6/U/fPgQOTk5ejVljfHoOh5X82j/0+ZSFqVSCZVKpfciIiKiZ6fWBhtHR0eo1WokJSVJbVqtFocPH4a3tzcAwNvbG7m5uUhNTZVq9uzZA51OBy8vL6nmwIEDKCoqkmoSExPRunVr1KtXT6p5dD0lNSXrKc9ciIiIqObVaLC5d+8ejh8/juPHjwP46yTd48eP4/Lly1AoFBg7dixmzZqFbdu2IT09HcOGDYOdnZ105ZSzszN69uyJUaNG4ciRIzh48CBCQ0MxaNAg2NnZAQCGDBkCY2NjBAcH4/Tp09iwYQOio6MRHh4uzWPMmDFISEjAggULcO7cOUybNg1Hjx5FaGgoAJRrLkRERFTzjGpy5UePHkX37t2l9yVhIygoCHFxcZg0aRLy8/MxevRo5Obm4rXXXkNCQgJMTEykZdauXYvQ0FD06NEDBgYG6NevHxYvXiz1W1pa4ueff0ZISAjc3d3RsGFDREVF6d3rpnPnzli3bh2++OILfPbZZ2jZsiW2bt2Ktm3bSjXlmQsRERHVrFpzH5uXAe9jQ/SS431s6GXC+9gQERERVQ2DDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyQaDDREREckGgw0RERHJBoMNERERyUatDjbFxcWIjIyEo6MjTE1N0bx5c8ycORNCCKlGCIGoqCjY2trC1NQUPj4+OH/+vN44OTk5CAwMhEqlgpWVFYKDg3Hv3j29mpMnT+L111+HiYkJ7O3tMW/evFLz2bRpE5ycnGBiYgJXV1fs3Lnz2Ww4ERERVUqtDjZz585FTEwMli5dirNnz2Lu3LmYN28elixZItXMmzcPixcvRmxsLA4fPgxzc3P4+fnhwYMHUk1gYCBOnz6NxMREbN++HQcOHMDo0aOlfq1WC19fXzRt2hSpqamYP38+pk2bhpUrV0o1hw4dwuDBgxEcHIxjx44hICAAAQEBOHXq1PPZGURERPRUCvHo4Y9apnfv3rCxscF3330ntfXr1w+mpqb44YcfIISAnZ0dxo8fjwkTJgAA8vLyYGNjg7i4OAwaNAhnz56Fi4sLUlJS4OHhAQBISEhAr169cPXqVdjZ2SEmJgaff/45NBoNjI2NAQBTpkzB1q1bce7cOQDAwIEDkZ+fj+3bt0tz6dSpE9zc3BAbG1uu7dFqtbC0tEReXh5UKlW17CMieoGsU9T0DIienyHVGy/K+zu0Vh+x6dy5M5KSkvDbb78BAE6cOIFff/0Vb7/9NgAgMzMTGo0GPj4+0jKWlpbw8vJCcnIyACA5ORlWVlZSqAEAHx8fGBgY4PDhw1JN165dpVADAH5+fsjIyMCdO3ekmkfXU1JTsp6yFBQUQKvV6r2IiIjo2TGq6Qk8yZQpU6DVauHk5ARDQ0MUFxdj9uzZCAwMBABoNBoAgI2Njd5yNjY2Up9Go4G1tbVev5GREerXr69X4+joWGqMkr569epBo9E8cT1lmTNnDqZPn17RzSYiIqJKqtVHbDZu3Ii1a9di3bp1SEtLw+rVq/H1119j9erVNT21comIiEBeXp70unLlSk1PiYiISNZq9RGbiRMnYsqUKRg0aBAAwNXVFZcuXcKcOXMQFBQEtVoNAMjKyoKtra20XFZWFtzc3AAAarUa2dnZeuM+fPgQOTk50vJqtRpZWVl6NSXvn1ZT0l8WpVIJpVJZ0c0mIiKiSqrVR2z+/PNPGBjoT9HQ0BA6nQ4A4OjoCLVajaSkJKlfq9Xi8OHD8Pb2BgB4e3sjNzcXqampUs2ePXug0+ng5eUl1Rw4cABFRUVSTWJiIlq3bo169epJNY+up6SmZD1ERERU82p1sHnnnXcwe/Zs7NixAxcvXkR8fDy++eYbvPfeewAAhUKBsWPHYtasWdi2bRvS09MxbNgw2NnZISAgAADg7OyMnj17YtSoUThy5AgOHjyI0NBQDBo0CHZ2dgCAIUOGwNjYGMHBwTh9+jQ2bNiA6OhohIeHS3MZM2YMEhISsGDBApw7dw7Tpk3D0aNHERoa+tz3CxEREZWtVl/ufffuXURGRiI+Ph7Z2dmws7PD4MGDERUVJV3BJITA1KlTsXLlSuTm5uK1117D8uXL0apVK2mcnJwchIaG4qeffoKBgQH69euHxYsXo27dulLNyZMnERISgpSUFDRs2BBhYWGYPHmy3nw2bdqEL774AhcvXkTLli0xb9489OrVq9zbw8u9iV5yvNybXiY1dLl3rQ42csNgQ/SSY7ChlwnvY0NERERUNQw2REREJBsMNkRERCQbDDZEREQkGww2REREJBsMNkRERCQbDDZEREQkGww2REREJBsMNkRERCQbDDZEREQkGww2REREJBsMNkRERCQbDDZEREQkGww2REREJBsMNkRERCQbDDZEREQkGww2REREJBsMNkRERCQbDDZEREQkGww2REREJBsMNkRERCQbDDZEREQkGww2REREJBuVCjbNmjXD7du3S7Xn5uaiWbNmVZ4UERERUWVUKthcvHgRxcXFpdoLCgpw7dq1Kk+KiIiIqDKMKlK8bds26c+7d++GpaWl9L64uBhJSUlwcHCotskRERERVUSFgk1AQAAAQKFQICgoSK+vTp06cHBwwIIFC6ptckREREQVUaFgo9PpAACOjo5ISUlBw4YNn8mkiIiIiCqjQsGmRGZmZnXPg6pAoajpGRA9P0LU9AyIqDarVLABgKSkJCQlJSE7O1s6klPi+++/r/LEiIiIiCqqUsFm+vTpmDFjBjw8PGBrawsFDxkQERFRLVCpYBMbG4u4uDgMHTq0uudDREREVGmVuo9NYWEhOnfuXN1zISIiIqqSSgWbDz/8EOvWravuuRARERFVSaW+inrw4AFWrlyJX375Be3atUOdOnX0+r/55ptqmRwRERFRRVQq2Jw8eRJubm4AgFOnTun18URiIiIiqimVCjZ79+6t7nkQERERVVmlzrEhIiIiqo0qdcSme/fuT/zKac+ePZWeEBEREVFlVeqIjZubG9q3by+9XFxcUFhYiLS0NLi6ulbrBK9du4YPPvgADRo0gKmpKVxdXXH06FGpXwiBqKgo2NrawtTUFD4+Pjh//rzeGDk5OQgMDIRKpYKVlRWCg4Nx7949vZqTJ0/i9ddfh4mJCezt7TFv3rxSc9m0aROcnJxgYmICV1dX7Ny5s1q3lYiIiKqmUkdsFi5cWGb7tGnTSgWGqrhz5w66dOmC7t27Y9euXWjUqBHOnz+PevXqSTXz5s3D4sWLsXr1ajg6OiIyMhJ+fn44c+YMTExMAACBgYG4ceMGEhMTUVRUhBEjRmD06NHSJetarRa+vr7w8fFBbGws0tPTMXLkSFhZWWH06NEAgEOHDmHw4MGYM2cOevfujXXr1iEgIABpaWlo27ZttW0zERERVZ5CiOp7pNzvv/+Ojh07Iicnp1rGmzJlCg4ePIj//ve/ZfYLIWBnZ4fx48djwoQJAIC8vDzY2NggLi4OgwYNwtmzZ+Hi4oKUlBR4eHgAABISEtCrVy9cvXoVdnZ2iImJweeffw6NRgNjY2Np3Vu3bsW5c+cAAAMHDkR+fj62b98urb9Tp05wc3NDbGxsubZHq9XC0tISeXl5UKlUld4vf8cL0ehl8kI/BHMdf1jpJTKken9Yy/s7tFpPHk5OTpaOklSHbdu2wcPDA++//z6sra3x6quv4ttvv5X6MzMzodFo4OPjI7VZWlrCy8sLycnJ0pysrKykUAMAPj4+MDAwwOHDh6Warl27SqEGAPz8/JCRkYE7d+5INY+up6SmZD1lKSgogFar1XsRERHRs1Opr6L69u2r914IgRs3buDo0aOIjIyslokBwB9//IGYmBiEh4fjs88+Q0pKCj799FMYGxsjKCgIGo0GAGBjY6O3nI2NjdSn0WhgbW2t129kZIT69evr1Tg6OpYao6SvXr160Gg0T1xPWebMmYPp06dXYsuJiIioMioVbCwtLfXeGxgYoHXr1pgxYwZ8fX2rZWIAoNPp4OHhgS+//BIA8Oqrr+LUqVOIjY1FUFBQta3nWYmIiEB4eLj0XqvVwt7evgZnREREJG+VCjarVq2q7nmUydbWFi4uLnptzs7O2LJlCwBArVYDALKysmBrayvVZGVlSXdGVqvVyM7O1hvj4cOHyMnJkZZXq9XIysrSqyl5/7Sakv6yKJVKKJXKcm0rERERVV2VzrFJTU3FDz/8gB9++AHHjh2rrjlJunTpgoyMDL223377DU2bNgUAODo6Qq1WIykpSerXarU4fPgwvL29AQDe3t7Izc1FamqqVLNnzx7odDp4eXlJNQcOHEBRUZFUk5iYiNatW0tXYHl7e+utp6SmZD1ERERU8yp1xCY7OxuDBg3Cvn37YGVlBQDIzc1F9+7dsX79ejRq1KhaJjdu3Dh07twZX375JQYMGIAjR45g5cqVWLlyJYC/nks1duxYzJo1Cy1btpQu97azs0NAQACAv47w9OzZE6NGjUJsbCyKiooQGhqKQYMGwc7ODgAwZMgQTJ8+HcHBwZg8eTJOnTqF6Ohovcvax4wZg27dumHBggXw9/fH+vXrcfToUWkuREREVPMqdcQmLCwMd+/exenTp5GTk4OcnBycOnUKWq0Wn376abVNztPTE/Hx8fjxxx/Rtm1bzJw5E4sWLUJgYKBUM2nSJISFhWH06NHw9PTEvXv3kJCQoHd11tq1a+Hk5IQePXqgV69eeO211/QCiaWlJX7++WdkZmbC3d0d48ePR1RUlHQPGwDo3Lkz1q1bh5UrV6J9+/bYvHkztm7dynvYEBER1SKVuo+NpaUlfvnlF3h6euq1HzlyBL6+vsjNza2u+ckK72NDVHW8jw3RC+JFuo+NTqdDnTp1SrXXqVMHOp2uMkMSERERVVmlgs2bb76JMWPG4Pr161LbtWvXMG7cOPTo0aPaJkdERERUEZUKNkuXLoVWq4WDgwOaN2+O5s2bw9HREVqtFkuWLKnuORIRERGVS6WuirK3t0daWhp++eUX6VlKzs7OpR45QERERPQ8VeiIzZ49e+Di4gKtVguFQoG33noLYWFhCAsLg6enJ9q0afPYB1YSERERPWsVCjaLFi3CqFGjyjwb2dLSEh999BG++eabapscERERUUVUKNicOHECPXv2fGy/r6+v3h1+iYiIiJ6nCgWbrKysMi/zLmFkZISbN29WeVJERERElVGhYNO4cWOcOnXqsf0nT57UexglERER0fNUoWDTq1cvREZG4sGDB6X67t+/j6lTp6J3797VNjkiIiKiiqjQIxWysrLQoUMHGBoaIjQ0FK1btwYAnDt3DsuWLUNxcTHS0tJgY2PzzCb8IuMjFYiqjo9UIHpB1NAjFSp0HxsbGxscOnQIH3/8MSIiIlCSiRQKBfz8/LBs2TKGGiIiIqoxFb5BX9OmTbFz507cuXMHv//+O4QQaNmyJerVq/cs5kdERERUbpW68zAA1KtXr9TTvYmIiIhqUqWeFUVERERUGzHYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWy8UMHmq6++gkKhwNixY6W2Bw8eICQkBA0aNEDdunXRr18/ZGVl6S13+fJl+Pv7w8zMDNbW1pg4cSIePnyoV7Nv3z506NABSqUSLVq0QFxcXKn1L1u2DA4ODjAxMYGXlxeOHDnyLDaTiIiIKumFCTYpKSlYsWIF2rVrp9c+btw4/PTTT9i0aRP279+P69evo2/fvlJ/cXEx/P39UVhYiEOHDmH16tWIi4tDVFSUVJOZmQl/f390794dx48fx9ixY/Hhhx9i9+7dUs2GDRsQHh6OqVOnIi0tDe3bt4efnx+ys7Of/cYTERFRuSiEEKKmJ/E09+7dQ4cOHbB8+XLMmjULbm5uWLRoEfLy8tCoUSOsW7cO/fv3BwCcO3cOzs7OSE5ORqdOnbBr1y707t0b169fh42NDQAgNjYWkydPxs2bN2FsbIzJkydjx44dOHXqlLTOQYMGITc3FwkJCQAALy8veHp6YunSpQAAnU4He3t7hIWFYcqUKeXaDq1WC0tLS+Tl5UGlUlXb/lEoqm0oolqv9v+L9QTr+MNKL5Eh1fvDWt7foS/EEZuQkBD4+/vDx8dHrz01NRVFRUV67U5OTnjllVeQnJwMAEhOToarq6sUagDAz88PWq0Wp0+flmr+Prafn580RmFhIVJTU/VqDAwM4OPjI9WUpaCgAFqtVu9FREREz45RTU/gadavX4+0tDSkpKSU6tNoNDA2NoaVlZVeu42NDTQajVTzaKgp6S/pe1KNVqvF/fv3cefOHRQXF5dZc+7cucfOfc6cOZg+fXr5NpSIiIiqrFYfsbly5QrGjBmDtWvXwsTEpKanU2ERERHIy8uTXleuXKnpKREREclarQ42qampyM7ORocOHWBkZAQjIyPs378fixcvhpGREWxsbFBYWIjc3Fy95bKysqBWqwEAarW61FVSJe+fVqNSqWBqaoqGDRvC0NCwzJqSMcqiVCqhUqn0XkRERPTs1Opg06NHD6Snp+P48ePSy8PDA4GBgdKf69Spg6SkJGmZjIwMXL58Gd7e3gAAb29vpKen6129lJiYCJVKBRcXF6nm0TFKakrGMDY2hru7u16NTqdDUlKSVENEREQ1r1afY2NhYYG2bdvqtZmbm6NBgwZSe3BwMMLDw1G/fn2oVCqEhYXB29sbnTp1AgD4+vrCxcUFQ4cOxbx586DRaPDFF18gJCQESqUSAPCPf/wDS5cuxaRJkzBy5Ejs2bMHGzduxI4dO6T1hoeHIygoCB4eHujYsSMWLVqE/Px8jBgx4jntDSIiInqaWh1symPhwoUwMDBAv379UFBQAD8/PyxfvlzqNzQ0xPbt2/Hxxx/D29sb5ubmCAoKwowZM6QaR0dH7NixA+PGjUN0dDSaNGmCf/7zn/Dz85NqBg4ciJs3byIqKgoajQZubm5ISEgodUIxERER1ZwX4j42csH72BBV3Qv9LxbvY0MvE97HhoiIiKhqGGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDYYbIiIiEg2GGyIiIhINhhsiIiISDZqdbCZM2cOPD09YWFhAWtrawQEBCAjI0Ov5sGDBwgJCUGDBg1Qt25d9OvXD1lZWXo1ly9fhr+/P8zMzGBtbY2JEyfi4cOHejX79u1Dhw4doFQq0aJFC8TFxZWaz7Jly+Dg4AATExN4eXnhyJEj1b7NREREVHm1Otjs378fISEh+N///ofExEQUFRXB19cX+fn5Us24cePw008/YdOmTdi/fz+uX7+Ovn37Sv3FxcXw9/dHYWEhDh06hNWrVyMuLg5RUVFSTWZmJvz9/dG9e3ccP34cY8eOxYcffojdu3dLNRs2bEB4eDimTp2KtLQ0tG/fHn5+fsjOzn4+O4OIiIieSiGEEDU9ifK6efMmrK2tsX//fnTt2hV5eXlo1KgR1q1bh/79+wMAzp07B2dnZyQnJ6NTp07YtWsXevfujevXr8PGxgYAEBsbi8mTJ+PmzZswNjbG5MmTsWPHDpw6dUpa16BBg5Cbm4uEhAQAgJeXFzw9PbF06VIAgE6ng729PcLCwjBlypRyzV+r1cLS0hJ5eXlQqVTVtl8UimobiqjWe3H+xSrDOv6w0ktkSPX+sJb3d2itPmLzd3l5eQCA+vXrAwBSU1NRVFQEHx8fqcbJyQmvvPIKkpOTAQDJyclwdXWVQg0A+Pn5QavV4vTp01LNo2OU1JSMUVhYiNTUVL0aAwMD+Pj4SDVlKSgogFar1XsRERHRs/PCBBudToexY8eiS5cuaNu2LQBAo9HA2NgYVlZWerU2NjbQaDRSzaOhpqS/pO9JNVqtFvfv38etW7dQXFxcZk3JGGWZM2cOLC0tpZe9vX3FN5yIiIjK7YUJNiEhITh16hTWr19f01Mpt4iICOTl5UmvK1eu1PSUiIiIZM2opidQHqGhodi+fTsOHDiAJk2aSO1qtRqFhYXIzc3VO2qTlZUFtVot1fz96qWSq6Yerfn7lVRZWVlQqVQwNTWFoaEhDA0Ny6wpGaMsSqUSSqWy4htMRERElVKrj9gIIRAaGor4+Hjs2bMHjo6Oev3u7u6oU6cOkpKSpLaMjAxcvnwZ3t7eAABvb2+kp6frXb2UmJgIlUoFFxcXqebRMUpqSsYwNjaGu7u7Xo1Op0NSUpJUQ0RERDWvVh+xCQkJwbp16/Cf//wHFhYW0vkslpaWMDU1haWlJYKDgxEeHo769etDpVIhLCwM3t7e6NSpEwDA19cXLi4uGDp0KObNmweNRoMvvvgCISEh0tGUf/zjH1i6dCkmTZqEkSNHYs+ePdi4cSN27NghzSU8PBxBQUHw8PBAx44dsWjRIuTn52PEiBHPf8cQERFRmWp1sImJiQEAvPHGG3rtq1atwvDhwwEACxcuhIGBAfr164eCggL4+flh+fLlUq2hoSG2b9+Ojz/+GN7e3jA3N0dQUBBmzJgh1Tg6OmLHjh0YN24coqOj0aRJE/zzn/+En5+fVDNw4EDcvHkTUVFR0Gg0cHNzQ0JCQqkTiomIiKjmvFD3sXnR8T42RFX3Qv+LxfvY0MuE97EhIiIiqhoGGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GmwpatmwZHBwcYGJiAi8vLxw5cqSmp0RERET/H4NNBWzYsAHh4eGYOnUq0tLS0L59e/j5+SE7O7ump0ZERERgsKmQb775BqNGjcKIESPg4uKC2NhYmJmZ4fvvv6/pqREREREAo5qewIuisLAQqampiIiIkNoMDAzg4+OD5OTkMpcpKChAQUGB9D4vLw8AoNVqn+1kiWTshf7x+bOmJ0D0HFXzD2vJ704hxBPrGGzK6datWyguLoaNjY1eu42NDc6dO1fmMnPmzMH06dNLtdvb2z+TORK9DCwta3oGRFQuo57ND+vdu3dh+YR/CBhsnqGIiAiEh4dL73U6HXJyctCgQQMoFIoanBlVlVarhb29Pa5cuQKVSlXT0yGix+DPqnwIIXD37l3Y2dk9sY7BppwaNmwIQ0NDZGVl6bVnZWVBrVaXuYxSqYRSqdRrs7KyelZTpBqgUqn4jyXRC4A/q/LwpCM1JXjycDkZGxvD3d0dSUlJUptOp0NSUhK8vb1rcGZERERUgkdsKiA8PBxBQUHw8PBAx44dsWjRIuTn52PEiBE1PTUiIiICg02FDBw4EDdv3kRUVBQ0Gg3c3NyQkJBQ6oRikj+lUompU6eW+qqRiGoX/qy+fBTiaddNEREREb0geI4NERERyQaDDREREckGgw0RERHJBoMNUQ2YNm0a3NzcanoaRC+dN954A2PHjq3padAzxGBDsjN8+HAoFAp89dVXeu1bt26t8h2f4+LioFAooFAoYGBgAFtbWwwcOBCXL1+u0DgTJkzQuycSET1dyc+2QqFAnTp14OjoiEmTJuHBgwflHuPf//43Zs6c+QxnSTWNwYZkycTEBHPnzsWdO3eqfWyVSoUbN27g2rVr2LJlCzIyMvD+++9XaIy6deuiQYMG1T43Irnr2bMnbty4gT/++AMLFy7EihUrMHXq1HIvX79+fVhYWDzDGVJNY7AhWfLx8YFarcacOXOeWLdlyxa0adMGSqUSDg4OWLBgwVPHVigUUKvVsLW1RefOnREcHIwjR47oPbV98uTJaNWqFczMzNCsWTNERkaiqKhI6v/7V1HDhw9HQEAAvv76a9ja2qJBgwYICQnRW4aI/rovjVqthr29PQICAuDj44PExEQAwO3btzF48GA0btwYZmZmcHV1xY8//qi3/N+/inJwcMCXX36JkSNHwsLCAq+88gpWrlz5PDeJqhmDDcmSoaEhvvzySyxZsgRXr14tsyY1NRUDBgzAoEGDkJ6ejmnTpiEyMhJxcXHlXk92djbi4+NhaGgIQ0NDqd3CwgJxcXE4c+YMoqOj8e2332LhwoVPHGvv3r24cOEC9u7di9WrVyMuLq5CcyF62Zw6dQqHDh2CsbExAODBgwdwd3fHjh07cOrUKYwePRpDhw7FkSNHnjjOggUL4OHhgWPHjuGTTz7Bxx9/jIyMjOexCfQsCCKZCQoKEu+++64QQohOnTqJkSNHCiGEiI+PF49+5IcMGSLeeustvWUnTpwoXFxcHjv2qlWrBABhbm4uzMzMBAABQHz66adPnNP8+fOFu7u79H7q1Kmiffv2enNu2rSpePjwodT2/vvvi4EDBz51e4leFkFBQcLQ0FCYm5sLpVIpAAgDAwOxefPmxy7j7+8vxo8fL73v1q2bGDNmjPS+adOm4oMPPpDe63Q6YW1tLWJiYp7JNtCzx0cqkKzNnTsXb775JiZMmFCq7+zZs3j33Xf12rp06YJFixahuLhY7wjMoywsLJCWloaioiLs2rULa9euxezZs/VqNmzYgMWLF+PChQu4d+8eHj58+NQnC7dp00Zvnba2tkhPTy/vphK9FLp3746YmBjk5+dj4cKFMDIyQr9+/QAAxcXF+PLLL7Fx40Zcu3YNhYWFKCgogJmZ2RPHbNeunfTnkq+as7Ozn+l20LPDr6JI1rp27Qo/Pz9ERERU25gGBgZo0aIFnJ2dER4ejk6dOuHjjz+W+pOTkxEYGIhevXph+/btOHbsGD7//HMUFhY+cdw6derovVcoFNDpdNU2byI5MDc3R4sWLdC+fXt8//33OHz4ML777jsAwPz58xEdHY3Jkydj7969OH78OPz8/Piz95LhERuSva+++gpubm5o3bq1XruzszMOHjyo13bw4EG0atXqsUdryjJlyhQ0b94c48aNQ4cOHXDo0CE0bdoUn3/+uVRz6dKlqm0EEZViYGCAzz77DOHh4RgyZAgOHjyId999Fx988AEAQKfT4bfffoOLi0sNz5SeJx6xIdlzdXVFYGAgFi9erNc+fvx4JCUlYebMmfjtt9+wevVqLF26tMyvrZ7E3t4e7733HqKiogAALVu2xOXLl7F+/XpcuHABixcvRnx8fLVtDxH9n/fffx+GhoZYtmwZWrZsicTERBw6dAhnz57FRx99hKysrJqeIj1nDDb0UpgxY0apQ8sdOnTAxo0bsX79erRt2xZRUVGYMWMGhg8fXuHxx40bhx07duDIkSPo06cPxo0bh9DQULi5ueHQoUOIjIyspi0hokcZGRkhNDQU8+bNw/jx49GhQwf4+fnhjTfegFqtRkBAQE1PkZ4zhRBC1PQkiIiIiKoDj9gQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BAREZFsMNgQERGRbDDYEBERkWww2BDRS0WhUGDr1q01PQ0iekYYbIhIVjQaDcLCwtCsWTMolUrY29vjnXfeQVJSUk1PjYieAz7dm4hk4+LFi+jSpQusrKwwf/58uLq6oqioCLt370ZISAjOnTtX01MkomeMR2yISDY++eQTKBQKHDlyBP369UOrVq3Qpk0bhIeH43//+1+Zy0yePBmtWrWCmZkZmjVrhsjISBQVFUn9J06cQPfu3WFhYQGVSgV3d3ccPXoUAHDp0iW88847qFevHszNzdGmTRvs3LnzuWwrEZWNR2yISBZycnKQkJCA2bNnw9zcvFS/lZVVmctZWFggLi4OdnZ2SE9Px6hRo2BhYYFJkyYBAAIDA/Hqq68iJiYGhoaGOH78OOrUqQMACAkJQWFhIQ4cOABzc3OcOXMGdevWfWbbSERPx2BDRLLw+++/QwgBJyenCi33xRdfSH92cHDAhAkTsH79einYXL58GRMnTpTGbdmypVR/+fJl9OvXD66urgCAZs2aVXUziKiK+FUUEcmCEKJSy23YsAFdunSBWq1G3bp18cUXX+Dy5ctSf3h4OD788EP4+Pjgq6++woULF6S+Tz/9FLNmzUKXLl0wdepUnDx5ssrbQURVw2BDRLLQsmVLKBSKCp0gnJycjMDAQPTq1Qvbt2/HsWPH8Pnnn6OwsFCqmTZtGk6fPg1/f3/s2bMHLi4uiI+PBwB8+OGH+OOPPzB06FCkp6fDw8MDS5YsqfZtI6LyU4jK/jeHiKiWefvtt5Geno6MjIxS59nk5ubCysoKCoUC8fHxCAgIwIIFC7B8+XK9ozAffvghNm/ejNzc3DLXMXjwYOTn52Pbtm2l+iIiIrBjxw4euSGqQTxiQ0SysWzZMhQXF6Njx47YsmULzp8/j7Nnz2Lx4sXw9vYuVd+yZUtcvnwZ69evx4ULF7B48WLpaAwA3L9/H6Ghodi3bx8uXbqEgwcPIiUlBc7OzgCAsWPHYvfu3cjMzERaWhr27t0r9RFRzeDJw0QkG82aNUNaWhpmz56N8ePH48aNG2jUqBHc3d0RExNTqr5Pnz4YN24cQkNDUVBQAH9/f0RGRmLatGkAAENDQ9y+fRvDhg1DVlYWGjZsiL59+2L69OkAgOLiYoSEhODq1atQqVTo2bMnFi5c+Dw3mYj+hl9FERERkWzwqygiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIikg0GGyIiIpINBhsiIiKSDQYbIiIiko3/B0jz1jpgUbJeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique_values, counts = np.unique(Target, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(unique_values, counts, color=['blue', 'orange'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('The balance of dataset before')\n",
    "plt.xticks(unique_values, ['No Rain', 'Rain'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "      super().__init__()\n",
    "      self.train = data\n",
    "      self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.train.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.train[index], self.label[index]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Data, Target, test_size=0.2)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to GPU\n",
    "TrainData = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "TrainLabel = torch.tensor(Y_train, dtype=torch.long, device=device)\n",
    "\n",
    "ValidData = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "ValidLabel = torch.tensor(Y_test, dtype=torch.long, device=device)\n",
    "\n",
    "# Create dataloader\n",
    "TrainDataset = CustomDataset(TrainData, TrainLabel)\n",
    "ValidDataset = CustomDataset(ValidData, ValidLabel)\n",
    "\n",
    "TrainDataloader = DataLoader(TrainDataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "ValidDataloader = DataLoader(ValidDataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.report = None\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, model, val_loss, val_acc, report):\n",
    "\n",
    "\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_acc = val_acc\n",
    "            self.report = report\n",
    "            ExportPATH = f'./ModelCheckpoint/SoftOrdering1DCNN.pth'\n",
    "            torch.save(model.state_dict(), ExportPATH)\n",
    "\n",
    "        elif val_loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best loss: {self.best_loss}')\n",
    "            print(f'Best accuracy: {self.best_acc}')\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_acc = val_acc\n",
    "            self.report = report\n",
    "            self.counter = 0\n",
    "            ExportPATH = f'./ModelCheckpoint/SoftOrdering1DCNN.pth'\n",
    "            torch.save(model.state_dict(), ExportPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, scheduler=None, schd_batch_update=False):\n",
    "        model.train()\n",
    "        running_loss = None\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for step, (data, label) in pbar:\n",
    "            scaler = GradScaler()\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, label)\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if running_loss is None:\n",
    "                    running_loss = loss.item()\n",
    "                else:\n",
    "                    running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "                if ((step + 1) %  2 == 0) or ((step + 1) == len(train_loader)):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if scheduler is not None and schd_batch_update:\n",
    "                        scheduler.step()\n",
    "\n",
    "                if ((step + 1) % 2 == 0) or ((step + 1) == len(train_loader)):\n",
    "                    description = f'Loss: {running_loss:.4f}'\n",
    "\n",
    "                    pbar.set_description(description)\n",
    "\n",
    "        if scheduler is not None and not schd_batch_update:\n",
    "           scheduler.step()\n",
    "\n",
    "def EvalModel(model, loss_fn, val_loader, early_stopping=None, scheduler=None, schd_loss_update=False):\n",
    "        model.eval()\n",
    "\n",
    "        loss_sum = 0\n",
    "        sample_num = 0\n",
    "        preds_all = []\n",
    "        targets_all = []\n",
    "\n",
    "        pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "        for step, (data, label) in pbar:\n",
    "            predict = model(data)\n",
    "            preds_all += [torch.argmax(predict, 1).detach().cpu().numpy()]\n",
    "            targets_all += [label.detach().cpu().numpy()]\n",
    "\n",
    "            loss = loss_fn(predict, label)\n",
    "\n",
    "            loss_sum += loss.item() * label.shape[0]\n",
    "            sample_num += label.shape[0]\n",
    "\n",
    "            if ((step + 1) % 2 == 0) or ((step + 1) == len(val_loader)):\n",
    "                description = f'Loss: {loss_sum/sample_num:.4f}'\n",
    "                pbar.set_description(description)\n",
    "\n",
    "        preds_all = np.concatenate(preds_all)\n",
    "        targets_all = np.concatenate(targets_all)\n",
    "\n",
    "        report = classification_report(targets_all, preds_all, digits=4)\n",
    "        print(\"Classification report\")\n",
    "        print(report)\n",
    "        print(\"F1 micro averaging:\",(f1_score(targets_all, preds_all, average='micro')))\n",
    "\n",
    "        ValidLoss = loss_sum/sample_num\n",
    "        ValidAcc = (preds_all==targets_all).mean()\n",
    "\n",
    "        print('Validation loss', ValidLoss)\n",
    "        print('Validation accuracy', ValidAcc)\n",
    "        if early_stopping != None:\n",
    "          early_stopping(model, ValidLoss, ValidAcc, report)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            if schd_loss_update:\n",
    "                scheduler.step(loss_sum/sample_num)\n",
    "            else:\n",
    "                scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 5\n",
      "Classes: 2\n",
      "Start building Model...\n",
      "Build Model successfully!\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5059: 100%|██████████| 2275/2275 [00:42<00:00, 53.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4801: 100%|██████████| 569/569 [00:04<00:00, 121.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8293    0.6580    0.7338     13302\n",
      "           1     0.8239    0.9220    0.8702     23090\n",
      "\n",
      "    accuracy                         0.8255     36392\n",
      "   macro avg     0.8266    0.7900    0.8020     36392\n",
      "weighted avg     0.8259    0.8255    0.8203     36392\n",
      "\n",
      "F1 micro averaging: 0.8254836227742361\n",
      "Validation loss 0.4800712869282108\n",
      "Validation accuracy 0.8254836227742361\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5028: 100%|██████████| 2275/2275 [00:40<00:00, 55.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4782: 100%|██████████| 569/569 [00:04<00:00, 128.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8342    0.6610    0.7376     13302\n",
      "           1     0.8256    0.9243    0.8722     23090\n",
      "\n",
      "    accuracy                         0.8281     36392\n",
      "   macro avg     0.8299    0.7927    0.8049     36392\n",
      "weighted avg     0.8287    0.8281    0.8230     36392\n",
      "\n",
      "F1 micro averaging: 0.8280666080457243\n",
      "Validation loss 0.47824738305541126\n",
      "Validation accuracy 0.8280666080457243\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5028: 100%|██████████| 2275/2275 [00:39<00:00, 56.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4754: 100%|██████████| 569/569 [00:04<00:00, 127.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8176    0.6897    0.7482     13302\n",
      "           1     0.8360    0.9113    0.8720     23090\n",
      "\n",
      "    accuracy                         0.8303     36392\n",
      "   macro avg     0.8268    0.8005    0.8101     36392\n",
      "weighted avg     0.8293    0.8303    0.8268     36392\n",
      "\n",
      "F1 micro averaging: 0.8303198505165971\n",
      "Validation loss 0.4753919992899732\n",
      "Validation accuracy 0.8303198505165971\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4971: 100%|██████████| 2275/2275 [00:40<00:00, 55.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4751: 100%|██████████| 569/569 [00:04<00:00, 123.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8263    0.6804    0.7463     13302\n",
      "           1     0.8329    0.9176    0.8732     23090\n",
      "\n",
      "    accuracy                         0.8309     36392\n",
      "   macro avg     0.8296    0.7990    0.8097     36392\n",
      "weighted avg     0.8305    0.8309    0.8268     36392\n",
      "\n",
      "F1 micro averaging: 0.8308969004176742\n",
      "Validation loss 0.47512263106786173\n",
      "Validation accuracy 0.8308969004176742\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4988: 100%|██████████| 2275/2275 [00:40<00:00, 56.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4764: 100%|██████████| 569/569 [00:04<00:00, 127.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8368    0.6609    0.7385     13302\n",
      "           1     0.8257    0.9257    0.8729     23090\n",
      "\n",
      "    accuracy                         0.8289     36392\n",
      "   macro avg     0.8312    0.7933    0.8057     36392\n",
      "weighted avg     0.8298    0.8289    0.8238     36392\n",
      "\n",
      "F1 micro averaging: 0.8289184436139811\n",
      "Validation loss 0.47636470672297565\n",
      "Validation accuracy 0.8289184436139811\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.47512263106786173\n",
      "Best accuracy: 0.8308969004176742\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4967: 100%|██████████| 2275/2275 [00:39<00:00, 57.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4740: 100%|██████████| 569/569 [00:04<00:00, 126.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8163    0.6970    0.7519     13302\n",
      "           1     0.8390    0.9097    0.8729     23090\n",
      "\n",
      "    accuracy                         0.8319     36392\n",
      "   macro avg     0.8277    0.8033    0.8124     36392\n",
      "weighted avg     0.8307    0.8319    0.8287     36392\n",
      "\n",
      "F1 micro averaging: 0.8319136073862388\n",
      "Validation loss 0.47397989959710507\n",
      "Validation accuracy 0.8319136073862388\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5012: 100%|██████████| 2275/2275 [00:40<00:00, 55.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4738: 100%|██████████| 569/569 [00:04<00:00, 125.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8055    0.7085    0.7539     13302\n",
      "           1     0.8430    0.9015    0.8712     23090\n",
      "\n",
      "    accuracy                         0.8309     36392\n",
      "   macro avg     0.8242    0.8050    0.8126     36392\n",
      "weighted avg     0.8293    0.8309    0.8283     36392\n",
      "\n",
      "F1 micro averaging: 0.8309243789843921\n",
      "Validation loss 0.4737578575743191\n",
      "Validation accuracy 0.8309243789843922\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5005: 100%|██████████| 2275/2275 [00:40<00:00, 56.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4739: 100%|██████████| 569/569 [00:04<00:00, 124.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8221    0.6864    0.7482     13302\n",
      "           1     0.8350    0.9144    0.8729     23090\n",
      "\n",
      "    accuracy                         0.8311     36392\n",
      "   macro avg     0.8286    0.8004    0.8105     36392\n",
      "weighted avg     0.8303    0.8311    0.8273     36392\n",
      "\n",
      "F1 micro averaging: 0.8310892503846999\n",
      "Validation loss 0.4738818351764893\n",
      "Validation accuracy 0.8310892503846999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4737578575743191\n",
      "Best accuracy: 0.8309243789843922\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 9 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5002: 100%|██████████| 2275/2275 [00:40<00:00, 56.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4739: 100%|██████████| 569/569 [00:04<00:00, 127.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7968    0.7206    0.7568     13302\n",
      "           1     0.8474    0.8942    0.8702     23090\n",
      "\n",
      "    accuracy                         0.8307     36392\n",
      "   macro avg     0.8221    0.8074    0.8135     36392\n",
      "weighted avg     0.8289    0.8307    0.8287     36392\n",
      "\n",
      "F1 micro averaging: 0.8307045504506485\n",
      "Validation loss 0.4739433094272773\n",
      "Validation accuracy 0.8307045504506485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4737578575743191\n",
      "Best accuracy: 0.8309243789843922\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 10 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4962: 100%|██████████| 2275/2275 [00:40<00:00, 56.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4745: 100%|██████████| 569/569 [00:04<00:00, 124.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7844    0.7368    0.7599     13302\n",
      "           1     0.8535    0.8833    0.8682     23090\n",
      "\n",
      "    accuracy                         0.8298     36392\n",
      "   macro avg     0.8189    0.8101    0.8140     36392\n",
      "weighted avg     0.8282    0.8298    0.8286     36392\n",
      "\n",
      "F1 micro averaging: 0.8297702791822379\n",
      "Validation loss 0.4745202375967756\n",
      "Validation accuracy 0.8297702791822379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.4737578575743191\n",
      "Best accuracy: 0.8309243789843922\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 11 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4986: 100%|██████████| 2275/2275 [00:40<00:00, 56.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4748: 100%|██████████| 569/569 [00:04<00:00, 126.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7896    0.7297    0.7585     13302\n",
      "           1     0.8508    0.8880    0.8690     23090\n",
      "\n",
      "    accuracy                         0.8301     36392\n",
      "   macro avg     0.8202    0.8089    0.8137     36392\n",
      "weighted avg     0.8284    0.8301    0.8286     36392\n",
      "\n",
      "F1 micro averaging: 0.8301275005495712\n",
      "Validation loss 0.47478805645189853\n",
      "Validation accuracy 0.8301275005495713\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best loss: 0.4737578575743191\n",
      "Best accuracy: 0.8309243789843922\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 12 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4934: 100%|██████████| 2275/2275 [00:40<00:00, 55.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4748: 100%|██████████| 569/569 [00:04<00:00, 126.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7822    0.7356    0.7582     13302\n",
      "           1     0.8527    0.8820    0.8671     23090\n",
      "\n",
      "    accuracy                         0.8285     36392\n",
      "   macro avg     0.8175    0.8088    0.8126     36392\n",
      "weighted avg     0.8269    0.8285    0.8273     36392\n",
      "\n",
      "F1 micro averaging: 0.8284787865464938\n",
      "Validation loss 0.4747523353974566\n",
      "Validation accuracy 0.8284787865464938\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Best loss: 0.4737578575743191\n",
      "Best accuracy: 0.8309243789843922\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 13 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5004: 100%|██████████| 2275/2275 [00:40<00:00, 56.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4733: 100%|██████████| 569/569 [00:04<00:00, 118.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8078    0.7073    0.7542     13302\n",
      "           1     0.8426    0.9030    0.8718     23090\n",
      "\n",
      "    accuracy                         0.8315     36392\n",
      "   macro avg     0.8252    0.8051    0.8130     36392\n",
      "weighted avg     0.8299    0.8315    0.8288     36392\n",
      "\n",
      "F1 micro averaging: 0.8314739503187515\n",
      "Validation loss 0.4733494750272575\n",
      "Validation accuracy 0.8314739503187514\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 14 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4957: 100%|██████████| 2275/2275 [00:40<00:00, 55.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4745: 100%|██████████| 569/569 [00:04<00:00, 123.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8032    0.7113    0.7545     13302\n",
      "           1     0.8440    0.8996    0.8709     23090\n",
      "\n",
      "    accuracy                         0.8308     36392\n",
      "   macro avg     0.8236    0.8055    0.8127     36392\n",
      "weighted avg     0.8291    0.8308    0.8284     36392\n",
      "\n",
      "F1 micro averaging: 0.8307869861508024\n",
      "Validation loss 0.47446352020675836\n",
      "Validation accuracy 0.8307869861508024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4733494750272575\n",
      "Best accuracy: 0.8314739503187514\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 15 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4994: 100%|██████████| 2275/2275 [00:41<00:00, 54.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4746: 100%|██████████| 569/569 [00:04<00:00, 127.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8220    0.6806    0.7447     13302\n",
      "           1     0.8326    0.9151    0.8719     23090\n",
      "\n",
      "    accuracy                         0.8294     36392\n",
      "   macro avg     0.8273    0.7979    0.8083     36392\n",
      "weighted avg     0.8287    0.8294    0.8254     36392\n",
      "\n",
      "F1 micro averaging: 0.8294130578149043\n",
      "Validation loss 0.47459179402105256\n",
      "Validation accuracy 0.8294130578149044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4733494750272575\n",
      "Best accuracy: 0.8314739503187514\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 16 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5019: 100%|██████████| 2275/2275 [00:45<00:00, 50.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4727: 100%|██████████| 569/569 [00:05<00:00, 106.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7980    0.7186    0.7562     13302\n",
      "           1     0.8467    0.8952    0.8703     23090\n",
      "\n",
      "    accuracy                         0.8306     36392\n",
      "   macro avg     0.8223    0.8069    0.8132     36392\n",
      "weighted avg     0.8289    0.8306    0.8286     36392\n",
      "\n",
      "F1 micro averaging: 0.8306495933172126\n",
      "Validation loss 0.47266481949434513\n",
      "Validation accuracy 0.8306495933172126\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 17 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5021: 100%|██████████| 2275/2275 [00:50<00:00, 45.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4730: 100%|██████████| 569/569 [00:06<00:00, 90.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7923    0.7267    0.7581     13302\n",
      "           1     0.8497    0.8903    0.8695     23090\n",
      "\n",
      "    accuracy                         0.8305     36392\n",
      "   macro avg     0.8210    0.8085    0.8138     36392\n",
      "weighted avg     0.8287    0.8305    0.8288     36392\n",
      "\n",
      "F1 micro averaging: 0.8304847219169048\n",
      "Validation loss 0.47302703101128163\n",
      "Validation accuracy 0.8304847219169048\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.47266481949434513\n",
      "Best accuracy: 0.8306495933172126\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 18 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5014: 100%|██████████| 2275/2275 [00:52<00:00, 43.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4734: 100%|██████████| 569/569 [00:06<00:00, 92.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7939    0.7243    0.7575     13302\n",
      "           1     0.8488    0.8916    0.8697     23090\n",
      "\n",
      "    accuracy                         0.8305     36392\n",
      "   macro avg     0.8213    0.8080    0.8136     36392\n",
      "weighted avg     0.8287    0.8305    0.8287     36392\n",
      "\n",
      "F1 micro averaging: 0.8304847219169048\n",
      "Validation loss 0.4734036200883546\n",
      "Validation accuracy 0.8304847219169048\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.47266481949434513\n",
      "Best accuracy: 0.8306495933172126\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 19 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4988: 100%|██████████| 2275/2275 [00:50<00:00, 44.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4730: 100%|██████████| 569/569 [00:06<00:00, 93.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7870    0.7378    0.7616     13302\n",
      "           1     0.8542    0.8850    0.8693     23090\n",
      "\n",
      "    accuracy                         0.8312     36392\n",
      "   macro avg     0.8206    0.8114    0.8155     36392\n",
      "weighted avg     0.8296    0.8312    0.8299     36392\n",
      "\n",
      "F1 micro averaging: 0.8311716860848538\n",
      "Validation loss 0.47303492596684565\n",
      "Validation accuracy 0.8311716860848538\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.47266481949434513\n",
      "Best accuracy: 0.8306495933172126\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 20 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4933: 100%|██████████| 2275/2275 [00:51<00:00, 44.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4753: 100%|██████████| 569/569 [00:06<00:00, 92.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7677    0.7585    0.7631     13302\n",
      "           1     0.8618    0.8677    0.8648     23090\n",
      "\n",
      "    accuracy                         0.8278     36392\n",
      "   macro avg     0.8147    0.8131    0.8139     36392\n",
      "weighted avg     0.8274    0.8278    0.8276     36392\n",
      "\n",
      "F1 micro averaging: 0.8278193009452627\n",
      "Validation loss 0.47532946213336275\n",
      "Validation accuracy 0.8278193009452627\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best loss: 0.47266481949434513\n",
      "Best accuracy: 0.8306495933172126\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 21 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5000: 100%|██████████| 2275/2275 [00:52<00:00, 43.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4738: 100%|██████████| 569/569 [00:06<00:00, 91.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7769    0.7476    0.7620     13302\n",
      "           1     0.8577    0.8764    0.8669     23090\n",
      "\n",
      "    accuracy                         0.8293     36392\n",
      "   macro avg     0.8173    0.8120    0.8144     36392\n",
      "weighted avg     0.8282    0.8293    0.8286     36392\n",
      "\n",
      "F1 micro averaging: 0.8292756649813144\n",
      "Validation loss 0.4738100005731815\n",
      "Validation accuracy 0.8292756649813146\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Best loss: 0.47266481949434513\n",
      "Best accuracy: 0.8306495933172126\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 22 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4966: 100%|██████████| 2275/2275 [00:53<00:00, 42.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4726: 100%|██████████| 569/569 [00:06<00:00, 92.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7939    0.7264    0.7586     13302\n",
      "           1     0.8497    0.8913    0.8700     23090\n",
      "\n",
      "    accuracy                         0.8310     36392\n",
      "   macro avg     0.8218    0.8088    0.8143     36392\n",
      "weighted avg     0.8293    0.8310    0.8293     36392\n",
      "\n",
      "F1 micro averaging: 0.831034293251264\n",
      "Validation loss 0.4726170010817237\n",
      "Validation accuracy 0.831034293251264\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 23 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5010: 100%|██████████| 2275/2275 [00:53<00:00, 42.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4736: 100%|██████████| 569/569 [00:06<00:00, 87.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7981    0.7197    0.7569     13302\n",
      "           1     0.8472    0.8951    0.8705     23090\n",
      "\n",
      "    accuracy                         0.8310     36392\n",
      "   macro avg     0.8227    0.8074    0.8137     36392\n",
      "weighted avg     0.8292    0.8310    0.8290     36392\n",
      "\n",
      "F1 micro averaging: 0.8310068146845461\n",
      "Validation loss 0.4735949919508902\n",
      "Validation accuracy 0.8310068146845461\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4726170010817237\n",
      "Best accuracy: 0.831034293251264\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 24 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4949: 100%|██████████| 2275/2275 [00:53<00:00, 42.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4732: 100%|██████████| 569/569 [00:06<00:00, 87.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7973    0.7230    0.7583     13302\n",
      "           1     0.8485    0.8941    0.8707     23090\n",
      "\n",
      "    accuracy                         0.8316     36392\n",
      "   macro avg     0.8229    0.8085    0.8145     36392\n",
      "weighted avg     0.8298    0.8316    0.8296     36392\n",
      "\n",
      "F1 micro averaging: 0.8315563860189052\n",
      "Validation loss 0.4732153031505787\n",
      "Validation accuracy 0.8315563860189052\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4726170010817237\n",
      "Best accuracy: 0.831034293251264\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 25 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5001: 100%|██████████| 2275/2275 [00:52<00:00, 42.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4725: 100%|██████████| 569/569 [00:06<00:00, 89.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7965    0.7224    0.7577     13302\n",
      "           1     0.8482    0.8937    0.8704     23090\n",
      "\n",
      "    accuracy                         0.8311     36392\n",
      "   macro avg     0.8224    0.8081    0.8140     36392\n",
      "weighted avg     0.8293    0.8311    0.8292     36392\n",
      "\n",
      "F1 micro averaging: 0.8310892503846999\n",
      "Validation loss 0.4725468205629954\n",
      "Validation accuracy 0.8310892503846999\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 26 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5007: 100%|██████████| 2275/2275 [00:58<00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4728: 100%|██████████| 569/569 [00:06<00:00, 86.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7889    0.7352    0.7611     13302\n",
      "           1     0.8532    0.8867    0.8696     23090\n",
      "\n",
      "    accuracy                         0.8313     36392\n",
      "   macro avg     0.8211    0.8109    0.8154     36392\n",
      "weighted avg     0.8297    0.8313    0.8300     36392\n",
      "\n",
      "F1 micro averaging: 0.8313090789184436\n",
      "Validation loss 0.47275329593984233\n",
      "Validation accuracy 0.8313090789184436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4725468205629954\n",
      "Best accuracy: 0.8310892503846999\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 27 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4954: 100%|██████████| 2275/2275 [00:54<00:00, 41.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4723: 100%|██████████| 569/569 [00:06<00:00, 87.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8083    0.7091    0.7555     13302\n",
      "           1     0.8435    0.9031    0.8723     23090\n",
      "\n",
      "    accuracy                         0.8322     36392\n",
      "   macro avg     0.8259    0.8061    0.8139     36392\n",
      "weighted avg     0.8306    0.8322    0.8296     36392\n",
      "\n",
      "F1 micro averaging: 0.8322158716201364\n",
      "Validation loss 0.4722949992328928\n",
      "Validation accuracy 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 28 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4973: 100%|██████████| 2275/2275 [00:52<00:00, 43.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4733: 100%|██████████| 569/569 [00:06<00:00, 86.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7856    0.7373    0.7607     13302\n",
      "           1     0.8539    0.8841    0.8687     23090\n",
      "\n",
      "    accuracy                         0.8305     36392\n",
      "   macro avg     0.8198    0.8107    0.8147     36392\n",
      "weighted avg     0.8289    0.8305    0.8292     36392\n",
      "\n",
      "F1 micro averaging: 0.8304572433501869\n",
      "Validation loss 0.473266549439555\n",
      "Validation accuracy 0.8304572433501869\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 29 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5020: 100%|██████████| 2275/2275 [00:53<00:00, 42.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4735: 100%|██████████| 569/569 [00:06<00:00, 87.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7899    0.7304    0.7590     13302\n",
      "           1     0.8512    0.8881    0.8692     23090\n",
      "\n",
      "    accuracy                         0.8305     36392\n",
      "   macro avg     0.8205    0.8093    0.8141     36392\n",
      "weighted avg     0.8288    0.8305    0.8289     36392\n",
      "\n",
      "F1 micro averaging: 0.8304572433501869\n",
      "Validation loss 0.47349122471928884\n",
      "Validation accuracy 0.8304572433501869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 30 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5013: 100%|██████████| 2275/2275 [00:54<00:00, 41.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4739: 100%|██████████| 569/569 [00:06<00:00, 85.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7745    0.7458    0.7599     13302\n",
      "           1     0.8566    0.8749    0.8657     23090\n",
      "\n",
      "    accuracy                         0.8277     36392\n",
      "   macro avg     0.8156    0.8104    0.8128     36392\n",
      "weighted avg     0.8266    0.8277    0.8270     36392\n",
      "\n",
      "F1 micro averaging: 0.8277368652451088\n",
      "Validation loss 0.4738597193833995\n",
      "Validation accuracy 0.8277368652451088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 31 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4954: 100%|██████████| 2275/2275 [00:52<00:00, 43.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4734: 100%|██████████| 569/569 [00:06<00:00, 87.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7842    0.7397    0.7613     13302\n",
      "           1     0.8548    0.8827    0.8685     23090\n",
      "\n",
      "    accuracy                         0.8304     36392\n",
      "   macro avg     0.8195    0.8112    0.8149     36392\n",
      "weighted avg     0.8290    0.8304    0.8293     36392\n",
      "\n",
      "F1 micro averaging: 0.830429764783469\n",
      "Validation loss 0.47337744114267405\n",
      "Validation accuracy 0.8304297647834689\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 32 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5023: 100%|██████████| 2275/2275 [00:55<00:00, 41.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4724: 100%|██████████| 569/569 [00:06<00:00, 84.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8092    0.7069    0.7546     13302\n",
      "           1     0.8426    0.9040    0.8722     23090\n",
      "\n",
      "    accuracy                         0.8319     36392\n",
      "   macro avg     0.8259    0.8054    0.8134     36392\n",
      "weighted avg     0.8304    0.8319    0.8292     36392\n",
      "\n",
      "F1 micro averaging: 0.8319410859529567\n",
      "Validation loss 0.47240756894630714\n",
      "Validation accuracy 0.8319410859529567\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 33 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5001: 100%|██████████| 2275/2275 [00:54<00:00, 41.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4727: 100%|██████████| 569/569 [00:06<00:00, 85.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8048    0.7115    0.7553     13302\n",
      "           1     0.8442    0.9006    0.8715     23090\n",
      "\n",
      "    accuracy                         0.8315     36392\n",
      "   macro avg     0.8245    0.8061    0.8134     36392\n",
      "weighted avg     0.8298    0.8315    0.8290     36392\n",
      "\n",
      "F1 micro averaging: 0.8315014288854693\n",
      "Validation loss 0.4727278796754897\n",
      "Validation accuracy 0.8315014288854693\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 34 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4994: 100%|██████████| 2275/2275 [00:54<00:00, 42.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4723: 100%|██████████| 569/569 [00:06<00:00, 86.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8040    0.7119    0.7552     13302\n",
      "           1     0.8443    0.9000    0.8713     23090\n",
      "\n",
      "    accuracy                         0.8313     36392\n",
      "   macro avg     0.8242    0.8060    0.8132     36392\n",
      "weighted avg     0.8296    0.8313    0.8289     36392\n",
      "\n",
      "F1 micro averaging: 0.8312816003517255\n",
      "Validation loss 0.4723307111808876\n",
      "Validation accuracy 0.8312816003517256\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 35 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4989: 100%|██████████| 2275/2275 [00:54<00:00, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4725: 100%|██████████| 569/569 [00:06<00:00, 87.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7928    0.7261    0.7580     13302\n",
      "           1     0.8495    0.8907    0.8696     23090\n",
      "\n",
      "    accuracy                         0.8305     36392\n",
      "   macro avg     0.8211    0.8084    0.8138     36392\n",
      "weighted avg     0.8288    0.8305    0.8288     36392\n",
      "\n",
      "F1 micro averaging: 0.8305122004836227\n",
      "Validation loss 0.47253936257276413\n",
      "Validation accuracy 0.8305122004836227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 36 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.4944: 100%|██████████| 2275/2275 [00:55<00:00, 41.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4735: 100%|██████████| 569/569 [00:06<00:00, 84.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7767    0.7477    0.7619     13302\n",
      "           1     0.8577    0.8762    0.8669     23090\n",
      "\n",
      "    accuracy                         0.8292     36392\n",
      "   macro avg     0.8172    0.8119    0.8144     36392\n",
      "weighted avg     0.8281    0.8292    0.8285     36392\n",
      "\n",
      "F1 micro averaging: 0.8292207078478786\n",
      "Validation loss 0.47350286089160676\n",
      "Validation accuracy 0.8292207078478786\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 37 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5014: 100%|██████████| 2275/2275 [00:56<00:00, 40.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4727: 100%|██████████| 569/569 [00:06<00:00, 85.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7976    0.7204    0.7570     13302\n",
      "           1     0.8474    0.8947    0.8704     23090\n",
      "\n",
      "    accuracy                         0.8310     36392\n",
      "   macro avg     0.8225    0.8075    0.8137     36392\n",
      "weighted avg     0.8292    0.8310    0.8290     36392\n",
      "\n",
      "F1 micro averaging: 0.8309793361178281\n",
      "Validation loss 0.4727475621800392\n",
      "Validation accuracy 0.8309793361178281\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Best loss: 0.4722949992328928\n",
      "Best accuracy: 0.8322158716201363\n",
      "\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from SoftOrdering1DCNN import SoftOrdering1DCNN\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch import nn\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "input_dim = TrainData.shape[1]\n",
    "numclass = len(np.unique(TrainLabel.cpu()))\n",
    "print(f'Feature: {input_dim}')\n",
    "print(f'Classes: {numclass}')\n",
    "\n",
    "print('Start building Model...')\n",
    "model = SoftOrdering1DCNN(input_dim, numclass)\n",
    "model.to(device)\n",
    "print('Build Model successfully!')\n",
    "\n",
    "from adabelief_pytorch import AdaBelief\n",
    "optimizer = AdaBelief(model.parameters(),\n",
    "                      lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decay=1e-4,\n",
    "                      weight_decouple=False, rectify=False, fixed_decay=False, amsgrad=False)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-4, last_epoch=-1)\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "loss_tr = nn.CrossEntropyLoss().to(device)\n",
    "loss_vl = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    epoch += 1\n",
    "    print('=================================================')\n",
    "    print(f'\\n[ TRAINING EPOCH {epoch} ]')\n",
    "    TrainModel(model, loss_tr, optimizer, TrainDataloader, scheduler=scheduler, schd_batch_update=True)\n",
    "    with torch.no_grad():\n",
    "      print('\\n[ EVALUATING VALIDATION ACCURACY ]')\n",
    "      EvalModel(model, loss_vl, ValidDataloader, early_stopping)\n",
    "      print('\\n-------------------------------------------------\\n')\n",
    "      if early_stopping.early_stop:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
