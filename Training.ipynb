{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181960 entries, 0 to 181959\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   province  181960 non-null  object \n",
      " 1   max       181960 non-null  int64  \n",
      " 2   min       181960 non-null  int64  \n",
      " 3   wind      181960 non-null  int64  \n",
      " 4   wind_d    181960 non-null  object \n",
      " 5   rain      181960 non-null  float64\n",
      " 6   humidi    181960 non-null  int64  \n",
      " 7   cloud     181960 non-null  int64  \n",
      " 8   pressure  181960 non-null  int64  \n",
      " 9   date      181960 non-null  object \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DataPath = './weather.csv'\n",
    "Dataframe = pd.read_csv(DataPath).reset_index(drop=True)\n",
    "\n",
    "Dataframe.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181960 entries, 0 to 181959\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   temp      181960 non-null  float64\n",
      " 1   wind      181960 non-null  float64\n",
      " 2   humidi    181960 non-null  int64  \n",
      " 3   cloud     181960 non-null  int64  \n",
      " 4   pressure  181960 non-null  int64  \n",
      " 5   israin    181960 non-null  int64  \n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 8.3 MB\n"
     ]
    }
   ],
   "source": [
    "Dataframe['temp'] = (Dataframe['max'] + Dataframe['min']) / 2\n",
    "NewDf = Dataframe[['temp', 'wind', 'humidi', 'cloud', 'pressure']]\n",
    "\n",
    "RainThreshold = 0.5\n",
    "NewDf['israin'] = (Dataframe['rain'] > RainThreshold).astype(int)\n",
    "\n",
    "NewDf['wind'] *= 0.277777778 # km/h to m/s\n",
    "\n",
    "NewDf.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>humidi</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "      <th>israin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.5</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.5</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.5</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp      wind  humidi  cloud  pressure  israin\n",
       "0  24.5  4.722222      90     71      1010       1\n",
       "1  28.0  5.555556      64     24      1010       0\n",
       "2  26.5  3.888889      75     45      1008       0\n",
       "3  27.0  8.333333      79     52      1012       0\n",
       "4  28.0  5.555556      70     24      1010       0\n",
       "5  25.5  3.888889      75     55      1012       0\n",
       "6  26.0  2.777778      75     42      1012       0\n",
       "7  28.0  6.111111      63      9      1015       0\n",
       "8  27.0  5.555556      76     35      1011       0\n",
       "9  26.0  4.444444      70     33      1010       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Data = NewDf.drop(columns='israin').values\n",
    "Target = NewDf['israin'].values\n",
    "\n",
    "np.save('./Data.npy', Data)\n",
    "np.save('./Target.npy', Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Standard scaling', StandardScaler()),\n",
    "     ('Normalize', Normalizer())]).fit(X=Data, y=Target)\n",
    "\n",
    "Data = pipeline.transform(X=Data)\n",
    "Target = LabelEncoder().fit_transform(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique_values, counts = np.unique(Target, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(unique_values, counts, color=['blue', 'orange'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('The balance of dataset before')\n",
    "plt.xticks(unique_values, ['No Rain', 'Rain'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "      super().__init__()\n",
    "      self.train = data\n",
    "      self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.train.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.train[index], self.label[index]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Data, Target, test_size=0.2)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to GPU\n",
    "TrainData = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "TrainLabel = torch.tensor(Y_train, dtype=torch.long, device=device)\n",
    "\n",
    "ValidData = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "ValidLabel = torch.tensor(Y_test, dtype=torch.long, device=device)\n",
    "\n",
    "# Create dataloader\n",
    "TrainDataset = CustomDataset(TrainData, TrainLabel)\n",
    "ValidDataset = CustomDataset(ValidData, ValidLabel)\n",
    "\n",
    "TrainDataloader = DataLoader(TrainDataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "ValidDataloader = DataLoader(ValidDataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.report = None\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, model, val_loss, val_acc, report):\n",
    "\n",
    "\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_acc = val_acc\n",
    "            self.report = report\n",
    "            ExportPATH = f'./ModelCheckpoint/SoftOrdering1DCNN.pth'\n",
    "            torch.save(model.state_dict(), ExportPATH)\n",
    "\n",
    "        elif val_loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best loss: {self.best_loss}')\n",
    "            print(f'Best accuracy: {self.best_acc}')\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_acc = val_acc\n",
    "            self.report = report\n",
    "            self.counter = 0\n",
    "            ExportPATH = f'./ModelCheckpoint/SoftOrdering1DCNN.pth'\n",
    "            torch.save(model.state_dict(), ExportPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, scheduler=None, schd_batch_update=False):\n",
    "        model.train()\n",
    "        running_loss = None\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for step, (data, label) in pbar:\n",
    "            scaler = GradScaler()\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, label)\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if running_loss is None:\n",
    "                    running_loss = loss.item()\n",
    "                else:\n",
    "                    running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "                if ((step + 1) %  2 == 0) or ((step + 1) == len(train_loader)):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if scheduler is not None and schd_batch_update:\n",
    "                        scheduler.step()\n",
    "\n",
    "                if ((step + 1) % 2 == 0) or ((step + 1) == len(train_loader)):\n",
    "                    description = f'Loss: {running_loss:.4f}'\n",
    "\n",
    "                    pbar.set_description(description)\n",
    "\n",
    "        if scheduler is not None and not schd_batch_update:\n",
    "           scheduler.step()\n",
    "\n",
    "def EvalModel(model, loss_fn, val_loader, early_stopping=None, scheduler=None, schd_loss_update=False):\n",
    "        model.eval()\n",
    "\n",
    "        loss_sum = 0\n",
    "        sample_num = 0\n",
    "        preds_all = []\n",
    "        targets_all = []\n",
    "\n",
    "        pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "        for step, (data, label) in pbar:\n",
    "            predict = model(data)\n",
    "            preds_all += [torch.argmax(predict, 1).detach().cpu().numpy()]\n",
    "            targets_all += [label.detach().cpu().numpy()]\n",
    "\n",
    "            loss = loss_fn(predict, label)\n",
    "\n",
    "            loss_sum += loss.item() * label.shape[0]\n",
    "            sample_num += label.shape[0]\n",
    "\n",
    "            if ((step + 1) % 2 == 0) or ((step + 1) == len(val_loader)):\n",
    "                description = f'Loss: {loss_sum/sample_num:.4f}'\n",
    "                pbar.set_description(description)\n",
    "\n",
    "        preds_all = np.concatenate(preds_all)\n",
    "        targets_all = np.concatenate(targets_all)\n",
    "\n",
    "        report = classification_report(targets_all, preds_all, digits=4)\n",
    "        print(\"Classification report\")\n",
    "        print(report)\n",
    "        print(\"F1 micro averaging:\",(f1_score(targets_all, preds_all, average='micro')))\n",
    "\n",
    "        ValidLoss = loss_sum/sample_num\n",
    "        ValidAcc = (preds_all==targets_all).mean()\n",
    "\n",
    "        print('Validation loss', ValidLoss)\n",
    "        print('Validation accuracy', ValidAcc)\n",
    "        if early_stopping != None:\n",
    "          early_stopping(model, ValidLoss, ValidAcc, report)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            if schd_loss_update:\n",
    "                scheduler.step(loss_sum/sample_num)\n",
    "            else:\n",
    "                scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 5\n",
      "Classes: 2\n",
      "Start building Model...\n",
      "Build Model successfully!\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5483: 100%|██████████| 2275/2275 [00:41<00:00, 55.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4783: 100%|██████████| 569/569 [00:04<00:00, 121.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8005    0.6997    0.7467     13249\n",
      "           1     0.8396    0.9002    0.8689     23143\n",
      "\n",
      "    accuracy                         0.8272     36392\n",
      "   macro avg     0.8201    0.7999    0.8078     36392\n",
      "weighted avg     0.8254    0.8272    0.8244     36392\n",
      "\n",
      "F1 micro averaging: 0.8271872939107496\n",
      "Validation loss 0.47827115206174414\n",
      "Validation accuracy 0.8271872939107496\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5496: 100%|██████████| 2275/2275 [00:40<00:00, 55.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4773: 100%|██████████| 569/569 [00:04<00:00, 124.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8018    0.7002    0.7476     13249\n",
      "           1     0.8400    0.9009    0.8694     23143\n",
      "\n",
      "    accuracy                         0.8278     36392\n",
      "   macro avg     0.8209    0.8006    0.8085     36392\n",
      "weighted avg     0.8261    0.8278    0.8250     36392\n",
      "\n",
      "F1 micro averaging: 0.8278467795119806\n",
      "Validation loss 0.477310809297178\n",
      "Validation accuracy 0.8278467795119806\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5416: 100%|██████████| 2275/2275 [00:40<00:00, 56.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4772: 100%|██████████| 569/569 [00:04<00:00, 122.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8057    0.6930    0.7451     13249\n",
      "           1     0.8373    0.9043    0.8695     23143\n",
      "\n",
      "    accuracy                         0.8274     36392\n",
      "   macro avg     0.8215    0.7987    0.8073     36392\n",
      "weighted avg     0.8258    0.8274    0.8242     36392\n",
      "\n",
      "F1 micro averaging: 0.8273796438777754\n",
      "Validation loss 0.4772375495217873\n",
      "Validation accuracy 0.8273796438777753\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5467: 100%|██████████| 2275/2275 [00:39<00:00, 57.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4779: 100%|██████████| 569/569 [00:04<00:00, 127.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8122    0.6794    0.7399     13249\n",
      "           1     0.8322    0.9101    0.8694     23143\n",
      "\n",
      "    accuracy                         0.8261     36392\n",
      "   macro avg     0.8222    0.7948    0.8047     36392\n",
      "weighted avg     0.8249    0.8261    0.8223     36392\n",
      "\n",
      "F1 micro averaging: 0.8261156298087491\n",
      "Validation loss 0.47787516460127294\n",
      "Validation accuracy 0.8261156298087492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4772375495217873\n",
      "Best accuracy: 0.8273796438777753\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5422: 100%|██████████| 2275/2275 [00:39<00:00, 57.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4765: 100%|██████████| 569/569 [00:04<00:00, 123.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7969    0.7114    0.7517     13249\n",
      "           1     0.8444    0.8962    0.8695     23143\n",
      "\n",
      "    accuracy                         0.8289     36392\n",
      "   macro avg     0.8206    0.8038    0.8106     36392\n",
      "weighted avg     0.8271    0.8289    0.8266     36392\n",
      "\n",
      "F1 micro averaging: 0.8289184436139811\n",
      "Validation loss 0.4765098363482106\n",
      "Validation accuracy 0.8289184436139811\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5494: 100%|██████████| 2275/2275 [00:40<00:00, 56.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4767: 100%|██████████| 569/569 [00:04<00:00, 123.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8080    0.6921    0.7455     13249\n",
      "           1     0.8371    0.9058    0.8701     23143\n",
      "\n",
      "    accuracy                         0.8280     36392\n",
      "   macro avg     0.8225    0.7989    0.8078     36392\n",
      "weighted avg     0.8265    0.8280    0.8248     36392\n",
      "\n",
      "F1 micro averaging: 0.8280116509122885\n",
      "Validation loss 0.4767466567916958\n",
      "Validation accuracy 0.8280116509122885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4765098363482106\n",
      "Best accuracy: 0.8289184436139811\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5420: 100%|██████████| 2275/2275 [00:40<00:00, 56.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4765: 100%|██████████| 569/569 [00:04<00:00, 121.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8096    0.6899    0.7450     13249\n",
      "           1     0.8363    0.9071    0.8703     23143\n",
      "\n",
      "    accuracy                         0.8280     36392\n",
      "   macro avg     0.8230    0.7985    0.8076     36392\n",
      "weighted avg     0.8266    0.8280    0.8247     36392\n",
      "\n",
      "F1 micro averaging: 0.8280391294790064\n",
      "Validation loss 0.476467345351307\n",
      "Validation accuracy 0.8280391294790064\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5431: 100%|██████████| 2275/2275 [00:43<00:00, 51.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4759: 100%|██████████| 569/569 [00:04<00:00, 121.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7949    0.7125    0.7515     13249\n",
      "           1     0.8446    0.8948    0.8690     23143\n",
      "\n",
      "    accuracy                         0.8284     36392\n",
      "   macro avg     0.8198    0.8036    0.8102     36392\n",
      "weighted avg     0.8265    0.8284    0.8262     36392\n",
      "\n",
      "F1 micro averaging: 0.8284238294130578\n",
      "Validation loss 0.4759343395811774\n",
      "Validation accuracy 0.8284238294130578\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 9 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5400: 100%|██████████| 2275/2275 [00:53<00:00, 42.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4774: 100%|██████████| 569/569 [00:07<00:00, 80.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8015    0.7038    0.7495     13249\n",
      "           1     0.8415    0.9002    0.8699     23143\n",
      "\n",
      "    accuracy                         0.8287     36392\n",
      "   macro avg     0.8215    0.8020    0.8097     36392\n",
      "weighted avg     0.8269    0.8287    0.8260     36392\n",
      "\n",
      "F1 micro averaging: 0.8286986150802375\n",
      "Validation loss 0.4773982436047934\n",
      "Validation accuracy 0.8286986150802375\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4759343395811774\n",
      "Best accuracy: 0.8284238294130578\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 10 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5453: 100%|██████████| 2275/2275 [00:54<00:00, 41.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4786: 100%|██████████| 569/569 [00:07<00:00, 80.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8344    0.6493    0.7303     13249\n",
      "           1     0.8219    0.9262    0.8709     23143\n",
      "\n",
      "    accuracy                         0.8254     36392\n",
      "   macro avg     0.8282    0.7878    0.8006     36392\n",
      "weighted avg     0.8264    0.8254    0.8198     36392\n",
      "\n",
      "F1 micro averaging: 0.8254286656408002\n",
      "Validation loss 0.47857447719018414\n",
      "Validation accuracy 0.8254286656408002\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4759343395811774\n",
      "Best accuracy: 0.8284238294130578\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 11 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5432: 100%|██████████| 2275/2275 [00:52<00:00, 43.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4759: 100%|██████████| 569/569 [00:07<00:00, 81.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8016    0.7044    0.7499     13249\n",
      "           1     0.8417    0.9002    0.8700     23143\n",
      "\n",
      "    accuracy                         0.8289     36392\n",
      "   macro avg     0.8217    0.8023    0.8099     36392\n",
      "weighted avg     0.8271    0.8289    0.8263     36392\n",
      "\n",
      "F1 micro averaging: 0.8289184436139811\n",
      "Validation loss 0.4759310546694915\n",
      "Validation accuracy 0.8289184436139811\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 12 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5409: 100%|██████████| 2275/2275 [00:52<00:00, 43.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4762: 100%|██████████| 569/569 [00:07<00:00, 79.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7929    0.7157    0.7523     13249\n",
      "           1     0.8458    0.8930    0.8688     23143\n",
      "\n",
      "    accuracy                         0.8284     36392\n",
      "   macro avg     0.8193    0.8043    0.8105     36392\n",
      "weighted avg     0.8265    0.8284    0.8264     36392\n",
      "\n",
      "F1 micro averaging: 0.8284238294130578\n",
      "Validation loss 0.47621818497092366\n",
      "Validation accuracy 0.8284238294130578\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4759310546694915\n",
      "Best accuracy: 0.8289184436139811\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 13 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5447: 100%|██████████| 2275/2275 [00:51<00:00, 44.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4764: 100%|██████████| 569/569 [00:06<00:00, 82.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7906    0.7210    0.7542     13249\n",
      "           1     0.8479    0.8907    0.8688     23143\n",
      "\n",
      "    accuracy                         0.8289     36392\n",
      "   macro avg     0.8193    0.8058    0.8115     36392\n",
      "weighted avg     0.8271    0.8289    0.8271     36392\n",
      "\n",
      "F1 micro averaging: 0.8288909650472631\n",
      "Validation loss 0.47637622118336886\n",
      "Validation accuracy 0.8288909650472631\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4759310546694915\n",
      "Best accuracy: 0.8289184436139811\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 14 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5441: 100%|██████████| 2275/2275 [00:49<00:00, 46.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4759: 100%|██████████| 569/569 [00:05<00:00, 96.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8048    0.7004    0.7490     13249\n",
      "           1     0.8403    0.9028    0.8704     23143\n",
      "\n",
      "    accuracy                         0.8291     36392\n",
      "   macro avg     0.8226    0.8016    0.8097     36392\n",
      "weighted avg     0.8274    0.8291    0.8262     36392\n",
      "\n",
      "F1 micro averaging: 0.8290833150142888\n",
      "Validation loss 0.4758509858332248\n",
      "Validation accuracy 0.8290833150142889\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 15 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5459: 100%|██████████| 2275/2275 [00:50<00:00, 45.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4783: 100%|██████████| 569/569 [00:05<00:00, 100.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8342    0.6577    0.7355     13249\n",
      "           1     0.8252    0.9252    0.8723     23143\n",
      "\n",
      "    accuracy                         0.8278     36392\n",
      "   macro avg     0.8297    0.7914    0.8039     36392\n",
      "weighted avg     0.8285    0.8278    0.8225     36392\n",
      "\n",
      "F1 micro averaging: 0.8277918223785448\n",
      "Validation loss 0.4783471984296192\n",
      "Validation accuracy 0.8277918223785448\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4758509858332248\n",
      "Best accuracy: 0.8290833150142889\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 16 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5432: 100%|██████████| 2275/2275 [00:57<00:00, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4760: 100%|██████████| 569/569 [00:05<00:00, 105.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8078    0.6971    0.7484     13249\n",
      "           1     0.8392    0.9050    0.8709     23143\n",
      "\n",
      "    accuracy                         0.8293     36392\n",
      "   macro avg     0.8235    0.8011    0.8096     36392\n",
      "weighted avg     0.8278    0.8293    0.8263     36392\n",
      "\n",
      "F1 micro averaging: 0.8293306221147505\n",
      "Validation loss 0.4759948480637631\n",
      "Validation accuracy 0.8293306221147505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4758509858332248\n",
      "Best accuracy: 0.8290833150142889\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 17 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5370: 100%|██████████| 2275/2275 [00:56<00:00, 40.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4764: 100%|██████████| 569/569 [00:04<00:00, 116.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8154    0.6828    0.7432     13249\n",
      "           1     0.8339    0.9115    0.8710     23143\n",
      "\n",
      "    accuracy                         0.8282     36392\n",
      "   macro avg     0.8246    0.7971    0.8071     36392\n",
      "weighted avg     0.8271    0.8282    0.8244     36392\n",
      "\n",
      "F1 micro averaging: 0.8282314794460321\n",
      "Validation loss 0.4763518834695839\n",
      "Validation accuracy 0.8282314794460321\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.4758509858332248\n",
      "Best accuracy: 0.8290833150142889\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 18 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5440: 100%|██████████| 2275/2275 [00:48<00:00, 46.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4762: 100%|██████████| 569/569 [00:04<00:00, 118.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8172    0.6820    0.7435     13249\n",
      "           1     0.8337    0.9127    0.8714     23143\n",
      "\n",
      "    accuracy                         0.8287     36392\n",
      "   macro avg     0.8255    0.7973    0.8075     36392\n",
      "weighted avg     0.8277    0.8287    0.8248     36392\n",
      "\n",
      "F1 micro averaging: 0.8286986150802375\n",
      "Validation loss 0.4762152427892209\n",
      "Validation accuracy 0.8286986150802375\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best loss: 0.4758509858332248\n",
      "Best accuracy: 0.8290833150142889\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 19 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5419: 100%|██████████| 2275/2275 [00:47<00:00, 48.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4757: 100%|██████████| 569/569 [00:04<00:00, 126.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7954    0.7174    0.7544     13249\n",
      "           1     0.8468    0.8944    0.8699     23143\n",
      "\n",
      "    accuracy                         0.8299     36392\n",
      "   macro avg     0.8211    0.8059    0.8122     36392\n",
      "weighted avg     0.8281    0.8299    0.8279     36392\n",
      "\n",
      "F1 micro averaging: 0.8299351505825455\n",
      "Validation loss 0.4757238049301689\n",
      "Validation accuracy 0.8299351505825456\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 20 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5443: 100%|██████████| 2275/2275 [00:45<00:00, 50.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4759: 100%|██████████| 569/569 [00:04<00:00, 121.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7901    0.7241    0.7557     13249\n",
      "           1     0.8493    0.8899    0.8691     23143\n",
      "\n",
      "    accuracy                         0.8295     36392\n",
      "   macro avg     0.8197    0.8070    0.8124     36392\n",
      "weighted avg     0.8277    0.8295    0.8278     36392\n",
      "\n",
      "F1 micro averaging: 0.8295229720817762\n",
      "Validation loss 0.4758609513655734\n",
      "Validation accuracy 0.8295229720817762\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.4757238049301689\n",
      "Best accuracy: 0.8299351505825456\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 21 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5394: 100%|██████████| 2275/2275 [00:45<00:00, 49.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4759: 100%|██████████| 569/569 [00:04<00:00, 124.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8033    0.7036    0.7502     13249\n",
      "           1     0.8416    0.9014    0.8705     23143\n",
      "\n",
      "    accuracy                         0.8294     36392\n",
      "   macro avg     0.8225    0.8025    0.8103     36392\n",
      "weighted avg     0.8277    0.8294    0.8267     36392\n",
      "\n",
      "F1 micro averaging: 0.8293855792481865\n",
      "Validation loss 0.4759151670245659\n",
      "Validation accuracy 0.8293855792481865\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.4757238049301689\n",
      "Best accuracy: 0.8299351505825456\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 22 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5416: 100%|██████████| 2275/2275 [00:46<00:00, 48.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4763: 100%|██████████| 569/569 [00:04<00:00, 126.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8214    0.6757    0.7414     13249\n",
      "           1     0.8314    0.9159    0.8716     23143\n",
      "\n",
      "    accuracy                         0.8284     36392\n",
      "   macro avg     0.8264    0.7958    0.8065     36392\n",
      "weighted avg     0.8278    0.8284    0.8242     36392\n",
      "\n",
      "F1 micro averaging: 0.8284238294130578\n",
      "Validation loss 0.4762879541796049\n",
      "Validation accuracy 0.8284238294130578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.4757238049301689\n",
      "Best accuracy: 0.8299351505825456\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 23 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5426: 100%|██████████| 2275/2275 [00:45<00:00, 49.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4755: 100%|██████████| 569/569 [00:04<00:00, 127.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8106    0.6934    0.7474     13249\n",
      "           1     0.8379    0.9072    0.8712     23143\n",
      "\n",
      "    accuracy                         0.8294     36392\n",
      "   macro avg     0.8242    0.8003    0.8093     36392\n",
      "weighted avg     0.8279    0.8294    0.8261     36392\n",
      "\n",
      "F1 micro averaging: 0.8293855792481865\n",
      "Validation loss 0.47553941946837847\n",
      "Validation accuracy 0.8293855792481865\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 24 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5401: 100%|██████████| 2275/2275 [00:44<00:00, 50.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4768: 100%|██████████| 569/569 [00:04<00:00, 128.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8151    0.6849    0.7444     13249\n",
      "           1     0.8347    0.9111    0.8712     23143\n",
      "\n",
      "    accuracy                         0.8287     36392\n",
      "   macro avg     0.8249    0.7980    0.8078     36392\n",
      "weighted avg     0.8276    0.8287    0.8250     36392\n",
      "\n",
      "F1 micro averaging: 0.8287260936469555\n",
      "Validation loss 0.47677047941469314\n",
      "Validation accuracy 0.8287260936469554\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.47553941946837847\n",
      "Best accuracy: 0.8293855792481865\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 25 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5396: 100%|██████████| 2275/2275 [00:45<00:00, 50.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4764: 100%|██████████| 569/569 [00:04<00:00, 125.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8198    0.6791    0.7428     13249\n",
      "           1     0.8327    0.9146    0.8717     23143\n",
      "\n",
      "    accuracy                         0.8288     36392\n",
      "   macro avg     0.8263    0.7968    0.8073     36392\n",
      "weighted avg     0.8280    0.8288    0.8248     36392\n",
      "\n",
      "F1 micro averaging: 0.8288360079138272\n",
      "Validation loss 0.47638925634182056\n",
      "Validation accuracy 0.8288360079138272\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.47553941946837847\n",
      "Best accuracy: 0.8293855792481865\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 26 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5439: 100%|██████████| 2275/2275 [00:46<00:00, 48.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4757: 100%|██████████| 569/569 [00:04<00:00, 124.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8021    0.7026    0.7491     13249\n",
      "           1     0.8410    0.9007    0.8699     23143\n",
      "\n",
      "    accuracy                         0.8286     36392\n",
      "   macro avg     0.8216    0.8017    0.8095     36392\n",
      "weighted avg     0.8269    0.8286    0.8259     36392\n",
      "\n",
      "F1 micro averaging: 0.8286161793800836\n",
      "Validation loss 0.4756984721568685\n",
      "Validation accuracy 0.8286161793800836\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.47553941946837847\n",
      "Best accuracy: 0.8293855792481865\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 27 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5383: 100%|██████████| 2275/2275 [00:45<00:00, 49.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4757: 100%|██████████| 569/569 [00:04<00:00, 126.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8052    0.7024    0.7503     13249\n",
      "           1     0.8412    0.9027    0.8709     23143\n",
      "\n",
      "    accuracy                         0.8298     36392\n",
      "   macro avg     0.8232    0.8026    0.8106     36392\n",
      "weighted avg     0.8281    0.8298    0.8270     36392\n",
      "\n",
      "F1 micro averaging: 0.8297977577489558\n",
      "Validation loss 0.4756569958671315\n",
      "Validation accuracy 0.8297977577489558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best loss: 0.47553941946837847\n",
      "Best accuracy: 0.8293855792481865\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 28 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5416: 100%|██████████| 2275/2275 [00:45<00:00, 50.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4749: 100%|██████████| 569/569 [00:04<00:00, 126.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8099    0.6968    0.7491     13249\n",
      "           1     0.8393    0.9064    0.8715     23143\n",
      "\n",
      "    accuracy                         0.8301     36392\n",
      "   macro avg     0.8246    0.8016    0.8103     36392\n",
      "weighted avg     0.8286    0.8301    0.8270     36392\n",
      "\n",
      "F1 micro averaging: 0.8300725434161356\n",
      "Validation loss 0.47488242758580895\n",
      "Validation accuracy 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 29 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5392: 100%|██████████| 2275/2275 [00:45<00:00, 50.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4754: 100%|██████████| 569/569 [00:04<00:00, 127.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8038    0.7042    0.7507     13249\n",
      "           1     0.8419    0.9016    0.8707     23143\n",
      "\n",
      "    accuracy                         0.8297     36392\n",
      "   macro avg     0.8228    0.8029    0.8107     36392\n",
      "weighted avg     0.8280    0.8297    0.8270     36392\n",
      "\n",
      "F1 micro averaging: 0.8297153220488019\n",
      "Validation loss 0.4753859026742836\n",
      "Validation accuracy 0.8297153220488019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 30 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5362: 100%|██████████| 2275/2275 [00:46<00:00, 49.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4753: 100%|██████████| 569/569 [00:04<00:00, 129.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7938    0.7201    0.7552     13249\n",
      "           1     0.8479    0.8929    0.8698     23143\n",
      "\n",
      "    accuracy                         0.8300     36392\n",
      "   macro avg     0.8208    0.8065    0.8125     36392\n",
      "weighted avg     0.8282    0.8300    0.8281     36392\n",
      "\n",
      "F1 micro averaging: 0.8299901077159816\n",
      "Validation loss 0.475304128357698\n",
      "Validation accuracy 0.8299901077159816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 31 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5437: 100%|██████████| 2275/2275 [00:45<00:00, 50.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4759: 100%|██████████| 569/569 [00:04<00:00, 127.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8109    0.6945    0.7482     13249\n",
      "           1     0.8384    0.9073    0.8715     23143\n",
      "\n",
      "    accuracy                         0.8298     36392\n",
      "   macro avg     0.8246    0.8009    0.8099     36392\n",
      "weighted avg     0.8284    0.8298    0.8266     36392\n",
      "\n",
      "F1 micro averaging: 0.8298252363156737\n",
      "Validation loss 0.4758793228561995\n",
      "Validation accuracy 0.8298252363156737\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 32 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5449: 100%|██████████| 2275/2275 [00:45<00:00, 50.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4761: 100%|██████████| 569/569 [00:04<00:00, 123.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8161    0.6878    0.7465     13249\n",
      "           1     0.8360    0.9112    0.8720     23143\n",
      "\n",
      "    accuracy                         0.8299     36392\n",
      "   macro avg     0.8261    0.7995    0.8093     36392\n",
      "weighted avg     0.8288    0.8299    0.8263     36392\n",
      "\n",
      "F1 micro averaging: 0.8299076720158276\n",
      "Validation loss 0.47607367059429234\n",
      "Validation accuracy 0.8299076720158276\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 33 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5399: 100%|██████████| 2275/2275 [00:45<00:00, 50.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4756: 100%|██████████| 569/569 [00:04<00:00, 121.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8046    0.7022    0.7499     13249\n",
      "           1     0.8411    0.9023    0.8707     23143\n",
      "\n",
      "    accuracy                         0.8295     36392\n",
      "   macro avg     0.8228    0.8023    0.8103     36392\n",
      "weighted avg     0.8278    0.8295    0.8267     36392\n",
      "\n",
      "F1 micro averaging: 0.8294954935150582\n",
      "Validation loss 0.4755800050362096\n",
      "Validation accuracy 0.8294954935150582\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 34 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5403: 100%|██████████| 2275/2275 [00:45<00:00, 50.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4768: 100%|██████████| 569/569 [00:04<00:00, 123.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8184    0.6752    0.7400     13249\n",
      "           1     0.8310    0.9142    0.8706     23143\n",
      "\n",
      "    accuracy                         0.8272     36392\n",
      "   macro avg     0.8247    0.7947    0.8053     36392\n",
      "weighted avg     0.8264    0.8272    0.8231     36392\n",
      "\n",
      "F1 micro averaging: 0.8272147724774676\n",
      "Validation loss 0.4768282283031173\n",
      "Validation accuracy 0.8272147724774676\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 35 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5428: 100%|██████████| 2275/2275 [00:45<00:00, 50.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4754: 100%|██████████| 569/569 [00:04<00:00, 126.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8097    0.6935    0.7471     13249\n",
      "           1     0.8378    0.9067    0.8709     23143\n",
      "\n",
      "    accuracy                         0.8291     36392\n",
      "   macro avg     0.8238    0.8001    0.8090     36392\n",
      "weighted avg     0.8276    0.8291    0.8258     36392\n",
      "\n",
      "F1 micro averaging: 0.8290558364475709\n",
      "Validation loss 0.4753767198377925\n",
      "Validation accuracy 0.8290558364475709\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 36 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5400: 100%|██████████| 2275/2275 [00:45<00:00, 49.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4757: 100%|██████████| 569/569 [00:04<00:00, 124.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8072    0.6958    0.7473     13249\n",
      "           1     0.8386    0.9049    0.8705     23143\n",
      "\n",
      "    accuracy                         0.8287     36392\n",
      "   macro avg     0.8229    0.8003    0.8089     36392\n",
      "weighted avg     0.8271    0.8287    0.8256     36392\n",
      "\n",
      "F1 micro averaging: 0.8287260936469555\n",
      "Validation loss 0.47572755358276275\n",
      "Validation accuracy 0.8287260936469554\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 37 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5465: 100%|██████████| 2275/2275 [00:45<00:00, 50.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4751: 100%|██████████| 569/569 [00:04<00:00, 124.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7988    0.7142    0.7541     13249\n",
      "           1     0.8457    0.8970    0.8706     23143\n",
      "\n",
      "    accuracy                         0.8305     36392\n",
      "   macro avg     0.8223    0.8056    0.8124     36392\n",
      "weighted avg     0.8286    0.8305    0.8282     36392\n",
      "\n",
      "F1 micro averaging: 0.8304572433501869\n",
      "Validation loss 0.4751036494321733\n",
      "Validation accuracy 0.8304572433501869\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "=================================================\n",
      "\n",
      "[ TRAINING EPOCH 38 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2275 [00:00<?, ?it/s]/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/vanlinh/NT131.O11.ATCL/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loss: 0.5426: 100%|██████████| 2275/2275 [00:45<00:00, 50.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ EVALUATING VALIDATION ACCURACY ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4752: 100%|██████████| 569/569 [00:04<00:00, 125.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8137    0.6902    0.7468     13249\n",
      "           1     0.8368    0.9095    0.8716     23143\n",
      "\n",
      "    accuracy                         0.8297     36392\n",
      "   macro avg     0.8252    0.7998    0.8092     36392\n",
      "weighted avg     0.8284    0.8297    0.8262     36392\n",
      "\n",
      "F1 micro averaging: 0.829660364915366\n",
      "Validation loss 0.4752087412194436\n",
      "Validation accuracy 0.829660364915366\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Best loss: 0.47488242758580895\n",
      "Best accuracy: 0.8300725434161355\n",
      "\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from SoftOrdering1DCNN import SoftOrdering1DCNN\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch import nn\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "input_dim = TrainData.shape[1]\n",
    "numclass = len(np.unique(TrainLabel.cpu()))\n",
    "print(f'Feature: {input_dim}')\n",
    "print(f'Classes: {numclass}')\n",
    "\n",
    "print('Start building Model...')\n",
    "model = SoftOrdering1DCNN(input_dim, numclass)\n",
    "model.to(device)\n",
    "print('Build Model successfully!')\n",
    "\n",
    "from adabelief_pytorch import AdaBelief\n",
    "optimizer = AdaBelief(model.parameters(),\n",
    "                      lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decay=1e-4,\n",
    "                      weight_decouple=False, rectify=False, fixed_decay=False, amsgrad=False)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-4, last_epoch=-1)\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "loss_tr = nn.CrossEntropyLoss().to(device)\n",
    "loss_vl = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    epoch += 1\n",
    "    print('=================================================')\n",
    "    print(f'\\n[ TRAINING EPOCH {epoch} ]')\n",
    "    TrainModel(model, loss_tr, optimizer, TrainDataloader, scheduler=scheduler, schd_batch_update=True)\n",
    "    with torch.no_grad():\n",
    "      print('\\n[ EVALUATING VALIDATION ACCURACY ]')\n",
    "      EvalModel(model, loss_vl, ValidDataloader, early_stopping)\n",
    "      print('\\n-------------------------------------------------\\n')\n",
    "      if early_stopping.early_stop:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
